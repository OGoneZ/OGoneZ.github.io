

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="https://img.zhubaoduo.com/logo_mini.png">
  <link rel="icon" href="https://img.zhubaoduo.com/logo_mini.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#191E23">
  <meta name="author" content="baoduozhu">
  <meta name="keywords" content="">
  
    <meta name="description" content="1 æŸå¤±å‡½æ•° æŸå¤±å‡½æ•°ï¼ˆloss functionï¼‰ï¼Œä¹Ÿå«ä»£ä»·å‡½æ•°ï¼ˆcost functionï¼‰ã€è¯¯å·®å‡½æ•°ï¼ˆerror functionï¼‰ã€ç›®æ ‡å‡½æ•°ï¼ˆobjective functionï¼‰ï¼Œæ˜¯ç”¨æ¥è¡¡é‡æ¨¡å‹å‚æ•°è´¨é‡çš„å‡½æ•°ï¼Œè¡¡é‡çš„æ–¹å¼æ˜¯æ¯”è¾ƒç½‘ç»œè¾“å‡ºï¼ˆé¢„æµ‹å€¼ï¼‰å’ŒçœŸå®è¾“å‡ºï¼ˆçœŸå®å€¼ï¼‰çš„å·®å¼‚ã€‚æ¨¡å‹é€šè¿‡æœ€å°åŒ–æŸå¤±å‡½æ•°çš„å€¼æ¥è°ƒæ•´å‚æ•°ï¼Œä½¿å…¶è¾“å‡ºæ›´æ¥è¿‘çœŸå®å€¼ã€‚ä¸»è¦æœ‰æ€§èƒ½è¯„ä¼°å’Œä¼˜åŒ–æŒ‡å¯¼ä¸¤å¤§ä½œç”¨ã€‚ 1.1 åˆ†ç±»ä»»">
<meta property="og:type" content="article">
<meta property="og:title" content="03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•">
<meta property="og:url" content="http://example.com/2024/08/07/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91/05%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/03_%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/index.html">
<meta property="og:site_name" content="æœ±å®é“çš„æŠ€æœ¯ä¸“æ ">
<meta property="og:description" content="1 æŸå¤±å‡½æ•° æŸå¤±å‡½æ•°ï¼ˆloss functionï¼‰ï¼Œä¹Ÿå«ä»£ä»·å‡½æ•°ï¼ˆcost functionï¼‰ã€è¯¯å·®å‡½æ•°ï¼ˆerror functionï¼‰ã€ç›®æ ‡å‡½æ•°ï¼ˆobjective functionï¼‰ï¼Œæ˜¯ç”¨æ¥è¡¡é‡æ¨¡å‹å‚æ•°è´¨é‡çš„å‡½æ•°ï¼Œè¡¡é‡çš„æ–¹å¼æ˜¯æ¯”è¾ƒç½‘ç»œè¾“å‡ºï¼ˆé¢„æµ‹å€¼ï¼‰å’ŒçœŸå®è¾“å‡ºï¼ˆçœŸå®å€¼ï¼‰çš„å·®å¼‚ã€‚æ¨¡å‹é€šè¿‡æœ€å°åŒ–æŸå¤±å‡½æ•°çš„å€¼æ¥è°ƒæ•´å‚æ•°ï¼Œä½¿å…¶è¾“å‡ºæ›´æ¥è¿‘çœŸå®å€¼ã€‚ä¸»è¦æœ‰æ€§èƒ½è¯„ä¼°å’Œä¼˜åŒ–æŒ‡å¯¼ä¸¤å¤§ä½œç”¨ã€‚ 1.1 åˆ†ç±»ä»»">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img.zhubaoduo.com/dl.jpg">
<meta property="article:published_time" content="2024-08-06T16:00:00.000Z">
<meta property="article:modified_time" content="2025-12-05T12:10:05.017Z">
<meta property="article:author" content="baoduozhu">
<meta property="article:tag" content="æ·±åº¦å­¦ä¹ ">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://img.zhubaoduo.com/dl.jpg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³• - æœ±å®é“çš„æŠ€æœ¯ä¸“æ </title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Zhubd</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>é¦–é¡µ</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>æ±‡æ€»</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>ä¸“é¢˜</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>æ ‡ç­¾</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://img.zhubaoduo.com/j35.gif') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-08-07 00:00" pubdate>
          2024å¹´8æœˆ7æ—¥ å‡Œæ™¨
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          8.5k å­—
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          107 åˆ†é’Ÿ
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar category-bar" style="margin-right: -1rem">
    





<div class="category-list">
  
  
    
    
    
    <div class="category row nomargin-x">
      <a class="category-item 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="æ·±åº¦å­¦ä¹ "
        id="heading-8c5f70f85d5a691a5f1dc7be5473736b" role="tab" data-toggle="collapse" href="#collapse-8c5f70f85d5a691a5f1dc7be5473736b"
        aria-expanded="true"
      >
        æ·±åº¦å­¦ä¹ 
        <span class="list-group-count">(5)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-8c5f70f85d5a691a5f1dc7be5473736b"
           role="tabpanel" aria-labelledby="heading-8c5f70f85d5a691a5f1dc7be5473736b">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/2024/08/03/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91/05%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01_%E5%BC%A0%E9%87%8F%E5%92%8C%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86/" title="01_å¼ é‡å’Œè‡ªåŠ¨å¾®åˆ†"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">01_å¼ é‡å’Œè‡ªåŠ¨å¾®åˆ†</span>
        </a>
      
    
      
      
        <a href="/2024/08/05/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91/05%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/" title="02_ç¥ç»ç½‘ç»œåŸºç¡€"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">02_ç¥ç»ç½‘ç»œåŸºç¡€</span>
        </a>
      
    
      
      
        <a href="/2024/08/07/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91/05%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/03_%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/" title="03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•"
           class="list-group-item list-group-item-action
           active">
          <span class="category-post">03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•</span>
        </a>
      
    
      
      
        <a href="/2024/08/09/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91/05%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/04_CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="04_CNNå·ç§¯ç¥ç»ç½‘ç»œ"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">04_CNNå·ç§¯ç¥ç»ç½‘ç»œ</span>
        </a>
      
    
      
      
        <a href="/2024/08/10/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91/05%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/05_RNN%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="05_RNNå¾ªç¯ç¥ç»ç½‘ç»œ"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">05_RNNå¾ªç¯ç¥ç»ç½‘ç»œ</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
</div>


  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="æŸå¤±å‡½æ•°">1 æŸå¤±å‡½æ•°</h1>
<p>æŸå¤±å‡½æ•°ï¼ˆloss functionï¼‰ï¼Œä¹Ÿå«ä»£ä»·å‡½æ•°ï¼ˆcost
functionï¼‰ã€è¯¯å·®å‡½æ•°ï¼ˆerror functionï¼‰ã€ç›®æ ‡å‡½æ•°ï¼ˆobjective
functionï¼‰ï¼Œæ˜¯ç”¨æ¥è¡¡é‡æ¨¡å‹å‚æ•°è´¨é‡çš„å‡½æ•°ï¼Œè¡¡é‡çš„æ–¹å¼æ˜¯æ¯”è¾ƒç½‘ç»œè¾“å‡ºï¼ˆé¢„æµ‹å€¼ï¼‰å’ŒçœŸå®è¾“å‡ºï¼ˆçœŸå®å€¼ï¼‰çš„å·®å¼‚ã€‚æ¨¡å‹é€šè¿‡æœ€å°åŒ–æŸå¤±å‡½æ•°çš„å€¼æ¥è°ƒæ•´å‚æ•°ï¼Œä½¿å…¶è¾“å‡ºæ›´æ¥è¿‘çœŸå®å€¼ã€‚ä¸»è¦æœ‰<strong>æ€§èƒ½è¯„ä¼°å’Œä¼˜åŒ–æŒ‡å¯¼</strong>ä¸¤å¤§ä½œç”¨ã€‚</p>
<h2 id="åˆ†ç±»ä»»åŠ¡">1.1 åˆ†ç±»ä»»åŠ¡</h2>
<h3 id="äºŒå…ƒäº¤å‰ç†µ">1.1.1 äºŒå…ƒäº¤å‰ç†µ</h3>
<p>äºŒåˆ†ç±»ä»»åŠ¡å¸¸ç”¨äºŒå…ƒäº¤å‰ç†µæŸå¤±å‡½æ•°ï¼ˆBinary Cross-Entropy Lossï¼‰ã€‚</p>
<p><span
class="math display">$$L=-\frac{1}{n}\sum_{i=1}^{n}\left(y_{i}\mathrm{log}\widehat{y}_{i}+(1-y_{i})\mathrm{log}(1-\widehat{y}_{i})\right)$$</span></p>
<ul>
<li><span class="math inline"><em>ğ‘¦</em><sub><em>ğ‘–</em></sub></span>
ä¸ºçœŸå®å€¼ï¼ˆé€šå¸¸ä¸º 0 æˆ– 1ï¼‰</li>
<li><span class="math inline"><em>ğ‘¦Ì‚</em><sub><em>ğ‘–</em></sub></span>
ä¸ºé¢„æµ‹å€¼ï¼ˆè¡¨ç¤ºæ ·æœ¬ ğ‘– ä¸º 1 çš„æ¦‚ç‡ï¼‰</li>
</ul>
<p>è¿™ä¸ªå…¬å¼æ˜¯é’ˆå¯¹å•ä¸ªæ ·æœ¬çš„ï¼Œå®ƒæ ¹æ®çœŸå®æ ‡ç­¾ <span
class="math inline"><em>y</em></span> çš„å–å€¼ï¼ˆ0 æˆ–
1ï¼‰åªä¿ç•™å…¶ä¸­ä¸€é¡¹æ¥è®¡ç®—æƒ©ç½šã€‚BCE
åªæƒ©ç½šæ¨¡å‹å¯¹æ­£ç¡®åˆ†ç±»çš„é¢„æµ‹æ¦‚ç‡ï¼Œé¢„æµ‹æ¦‚ç‡è¶Šå¤§ï¼ŒæŸå¤±è¶Šå°ã€‚</p>
<p>ä½¿ç”¨ sigmoid
æ¿€æ´»å‡½æ•°åœ¨è¾“å‡ºå±‚è¿›è¡ŒäºŒåˆ†ç±»æ—¶ï¼Œè¾“å‡ºå±‚åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œè¿™ä¸ªèŠ‚ç‚¹çš„è¾“å‡ºè¡¨ç¤ºæ ·æœ¬å±äºç±»
1 çš„æ¦‚ç‡ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br>torch.manual_seed(<span class="hljs-number">66</span>)<br><br><span class="hljs-comment"># çœŸå®æ ‡ç­¾ï¼Œå¿…é¡»ä¸º one-hot ç¼–ç ï¼Œä¸”å¿…é¡»ä¸ºæµ®ç‚¹æ•°</span><br>y_true = torch.tensor([[<span class="hljs-number">1</span>], [<span class="hljs-number">0</span>], [<span class="hljs-number">0</span>]], dtype=torch.<span class="hljs-built_in">float</span>)<br><span class="hljs-comment"># æœ€åä¸€å±‚çš„è¾“å…¥</span><br>last_in = torch.rand(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br><span class="hljs-comment"># é¢„æµ‹ç»“æœï¼Œè¡¨ç¤ºæ¨¡å‹é¢„æµ‹ä¸º 1 çš„æ¦‚ç‡</span><br>y_pred = torch.sigmoid(last_in)<br><br>criterion = nn.BCELoss()<br>loss = criterion(y_pred, y_true)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;é¢„æµ‹æ¦‚ç‡ä¸º 1 çš„æ¦‚ç‡ä¸ºï¼š\n<span class="hljs-subst">&#123;y_pred&#125;</span>\næŸå¤±ä¸ºï¼š<span class="hljs-subst">&#123;loss:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">é¢„æµ‹æ¦‚ç‡ä¸º 1 çš„æ¦‚ç‡ä¸ºï¼š
tensor([[0.6219],
        [0.5057],
        [0.5565]])
æŸå¤±ä¸ºï¼š0.664</code></pre>
<h3 id="å¤šåˆ†ç±»äº¤å‰ç†µ">1.1.2 å¤šåˆ†ç±»äº¤å‰ç†µ</h3>
<p>å¤šåˆ†ç±»ä»»åŠ¡å¸¸ç”¨å¤šåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼ˆCategorical Cross-Entropy
Lossï¼‰ã€‚</p>
<p><span
class="math display">$$L=-\frac{1}{n}\sum_{i=1}^n\sum_{c=1}^Cy_{i,c}\log\widehat{y_{i,c}}$$</span></p>
<ul>
<li><span class="math inline"><em>C</em></span> ä¸ºç±»åˆ«æ•°</li>
<li><span
class="math inline"><em>y</em><sub><em>i</em>,â€†<em>c</em></sub></span>
è¡¨ç¤ºç¬¬ <span class="math inline"><em>i</em></span> ä¸ªæ ·æœ¬æ˜¯å¦ä¸º <span
class="math inline"><em>c</em></span> ç±»ï¼Œä½¿ç”¨ç‹¬çƒ­ç¼–ç  0 æˆ– 1</li>
<li><span class="math inline">$\widehat{y_{i,c}}$</span> è¡¨ç¤ºç¬¬ <span
class="math inline"><em>i</em></span> ä¸ªæ ·æœ¬æ˜¯ç±»åˆ« <span
class="math inline"><em>c</em></span> çš„é¢„æµ‹æ¦‚ç‡</li>
</ul>
<p><img
src="https://img.zhubaoduo.com/03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•-cross_entropy.png" srcset="/img/loading.gif" lazyload /></p>
<p>è¿™ä¸ªå…¬å¼æ˜¯é’ˆå¯¹ <span class="math inline"><em>C</em></span>
ä¸ªç±»åˆ«çš„å¤šåˆ†ç±»é—®é¢˜ï¼Œå®ƒåˆ©ç”¨äº† One-Hot
ç¼–ç çš„ç‰¹æ€§ï¼Œåªä¿ç•™å…¶ä¸­ä¸€é¡¹æ¥è®¡ç®—æƒ©ç½šï¼ŒCCE åªæƒ©ç½šå¯¹çœŸå®ç±»åˆ« <span
class="math inline"><em>c</em></span> çš„é¢„æµ‹æ¦‚ç‡ <span
class="math inline">$\widehat{y_{i,c}}$</span>ï¼Œç›¸å½“äºå¯¹æ¯ä¸€ä¸ªæ ·æœ¬çš„æ­£ç¡®æ ‡ç­¾é¢„æµ‹æ¦‚ç‡å€¼å–
log ï¼Œç„¶åæ±‚å’Œã€‚</p>
<p>ä½¿ç”¨ softmax
è¿›è¡Œå¤šåˆ†ç±»æ—¶ï¼Œæœ‰å‡ ä¸ªåˆ†ç±»ï¼Œè¾“å‡ºå±‚å°±æœ‰å‡ ä¸ªç¥ç»å…ƒï¼Œæ¯ä¸ªç¥ç»å…ƒè¾“å‡ºä¸€ä¸ªåˆ†ç±»çš„æ¦‚ç‡ï¼Œæ‰€æœ‰æ¦‚ç‡å’Œä¸º
1ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># æ‰‹åŠ¨å®ç°ï¼Œy_predä¸º softmaw è¾“å‡ºé¢„æµ‹å€¼ï¼Œy_true ä¸ºçœŸå®æ ‡ç­¾æˆ–ç‹¬çƒ­ç¼–ç æ ‡ç­¾</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cross_entropy_loss</span>(<span class="hljs-params">y_pred, y_true</span>):<br>    <span class="hljs-comment"># å¦‚æœäºŒè€…å½¢çŠ¶ä¸€è‡´ï¼Œåˆ™è¯´æ˜ y_true ä¸ºç‹¬çƒ­ç¼–ç æ ‡ç­¾</span><br>    <span class="hljs-keyword">if</span> y_pred.size == y_true.size:<br>        y_true = y_true.argmaw(dim=<span class="hljs-number">1</span>)  <span class="hljs-comment"># è½¬æ¢ä¸ºçœŸå®æ ‡ç­¾ç´¢å¼•</span><br>    <br>    <span class="hljs-comment"># n è¡Œä»£è¡¨ n ä¸ªæ ·æœ¬</span><br>    n = y_pred.shape[<span class="hljs-number">0</span>]<br>    <br>    <span class="hljs-comment"># åŠ ä¸Šä¸€ä¸ªå°å¸¸æ•°ï¼Œé˜²æ­¢ log(0)</span><br>    <span class="hljs-keyword">return</span> -np.<span class="hljs-built_in">sum</span>(np.log(y_pred[np.arange(n), y_true] + <span class="hljs-number">1e-7</span>)) / n<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># çœŸå®å€¼ä¸ºæ ‡ç­¾ï¼šå¿…é¡»æ˜¯ä¸€ç»´çš„ï¼Œå¹¶ä¸”å¿…é¡»æ˜¯ 64 ä½é•¿æ•´å‹</span><br>y_true = torch.tensor([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>])<br><span class="hljs-comment"># æœ€åä¸€å±‚çš„è¾“å…¥çŸ©é˜µï¼Œå…± 3 ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬ 5 ä¸ªç‰¹å¾ï¼Œå¯¹åº”æœ€ç»ˆè¾“å‡ºå±‚çš„ 5 ä¸ªç±»åˆ«</span><br>last_in = torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br><span class="hljs-comment"># ç»è¿‡ softmaw æ¿€æ´»ï¼ŒCrossEntropyLoss ä¸éœ€è¦æ­¤æ­¥éª¤</span><br>y_pred = torch.softmax(last_in, dim=-<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># CrossEntropyLoss(Logits, Target) = NLLLoss(softmax(Logits)ï¼ŒTarget)</span><br>criterion = nn.CrossEntropyLoss()<br>loss = criterion(last_in, y_true)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;é¢„æµ‹æ¦‚ç‡ï¼š\n<span class="hljs-subst">&#123;y_pred&#125;</span>\n æŸå¤±ï¼š<span class="hljs-subst">&#123;loss:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;è‡ªå®šä¹‰äº¤å‰ç†µæŸå¤±ï¼š<span class="hljs-subst">&#123;cross_entropy_loss(y_pred.detach().numpy(), y_true.detach().numpy())&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">é¢„æµ‹æ¦‚ç‡ï¼š
tensor([[0.0875, 0.1952, 0.2651, 0.3005, 0.1516],
        [0.1701, 0.5141, 0.1368, 0.0314, 0.1476],
        [0.3212, 0.2801, 0.0933, 0.1782, 0.1272]])
 æŸå¤±ï¼š1.463
è‡ªå®šä¹‰äº¤å‰ç†µæŸå¤±ï¼š1.4625852902730305</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># çœŸå®å€¼ä¸ºæ¦‚ç‡ï¼š</span><br>y_true = torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>).softmax(dim=-<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;çœŸå®å€¼ï¼š\n<span class="hljs-subst">&#123;y_true&#125;</span>&#x27;</span>)<br><br>loss = criterion(last_in, y_true)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;é¢„æµ‹æ¦‚ç‡ï¼š\n<span class="hljs-subst">&#123;y_pred&#125;</span>\n æŸå¤±ï¼š<span class="hljs-subst">&#123;loss:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">çœŸå®å€¼ï¼š
tensor([[0.3730, 0.2605, 0.1388, 0.1145, 0.1133],
        [0.0738, 0.0385, 0.4177, 0.2543, 0.2157],
        [0.3849, 0.4449, 0.0261, 0.1309, 0.0132]])
é¢„æµ‹æ¦‚ç‡ï¼š
tensor([[0.0875, 0.1952, 0.2651, 0.3005, 0.1516],
        [0.1701, 0.5141, 0.1368, 0.0314, 0.1476],
        [0.3212, 0.2801, 0.0933, 0.1782, 0.1272]])
 æŸå¤±ï¼š1.823</code></pre>
<blockquote>
<p>æ³¨æ„ï¼š<code>CrossEntropyLoss</code> å†…éƒ¨å®Œæˆäº† softmax
æ“ä½œå’Œè®¡ç®—æŸå¤±ï¼Œå› æ­¤ä¸éœ€è¦å†è¿›è¡Œ softmax
æ“ä½œï¼Œå¹¶ä¸”è¿”å›çš„æ˜¯ä¸€æ‰¹æ¬¡çš„å¹³å‡æŸå¤±ï¼Œç»“æœæ˜¯æ ‡é‡ã€‚<code>CrossEntropyLoss</code>
ç­‰ä»·äº <code>LogSoftmax</code> + <code>NLLLoss</code>ã€‚</p>
</blockquote>
<h2 id="å›å½’ä»»åŠ¡">1.2 å›å½’ä»»åŠ¡</h2>
<h3 id="mael1-loss">1.2.1 MAE(L1 Loss)</h3>
<p>å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMean Absolute Errorï¼ŒMAEï¼‰ï¼Œä¹Ÿç§° L1 Lossã€‚</p>
<p><span
class="math display">$$L=\frac{1}{n}\sum_{i=1}^n|y_i-\hat{y_i}|$$</span></p>
<p>L1 Losså¯¹å¼‚å¸¸å€¼ä¸å¤ªæ•æ„Ÿï¼Œ0
ç‚¹ä¸å¯å¯¼ï¼Œäº§ç”Ÿç¨€ç–çŸ©é˜µï¼Œå¸¸å¸¸ä½œä¸ºæ­£åˆ™åŒ–é¡¹æ·»åŠ åˆ°å…¶ä»–æŸå¤±å‡½æ•°ä¸­ã€‚ ä½†æ˜¯L1
Loss æœ€å¤§çš„é—®é¢˜å°±æ˜¯åœ¨ 0 å¤„ä¸å¹³æ»‘ï¼Œåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ä¼šè·³è¿‡æå°å€¼ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">y_true = torch.tensor([<span class="hljs-number">5.0</span>, <span class="hljs-number">6.2</span>, <span class="hljs-number">3.5</span>, <span class="hljs-number">4.0</span>])<br>y_pred = torch.tensor([<span class="hljs-number">5.5</span>, <span class="hljs-number">9.2</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>])<br><br>criterion = nn.L1Loss()<br>loss = criterion(y_true, y_pred)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;L1Loss: <span class="hljs-subst">&#123;loss.item():<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">L1Loss: 1.000</code></pre>
<h3 id="msel2-loss">1.2.2 MSE(L2 Loss)</h3>
<p>å‡æ–¹è¯¯å·®ï¼ˆMean Squared Error ï¼ŒMSEï¼‰ï¼Œä¹Ÿç§° L2 Lossã€‚</p>
<p><span
class="math display">$$L=\frac{1}{n}\sum_{i=1}^{n}(y_{i}-\widehat{y}_{i})^{2}$$</span></p>
<p>L2 Loss
ç”±äºå¹³æ–¹ä¼šæ”¾å¤§è¯¯å·®ï¼Œå› æ­¤å¯¹ç¦»ç¾¤ç‚¹æ•æ„Ÿï¼Œå½“é¢„æµ‹å€¼ä¸çœŸå®å€¼åå·®è¾ƒå¤§æ—¶ï¼Œå®¹æ˜“å‘ç”Ÿæ¢¯åº¦çˆ†ç‚¸ã€‚ä¹Ÿå¸¸å¸¸ä½œä¸ºæ­£åˆ™åŒ–é¡¹ã€‚</p>
<p>æ¢¯åº¦çˆ†ç‚¸:ç½‘ç»œå±‚ä¹‹é—´çš„æ¢¯åº¦ï¼ˆå€¼å¤§äº1.0ï¼‰é‡å¤ç›¸ä¹˜å¯¼è‡´çš„æŒ‡æ•°çº§å¢é•¿ä¼šäº§ç”Ÿæ¢¯åº¦çˆ†ç‚¸ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">y_true = torch.tensor([<span class="hljs-number">5.0</span>, <span class="hljs-number">6.2</span>, <span class="hljs-number">3.5</span>, <span class="hljs-number">4.0</span>])<br>y_pred = torch.tensor([<span class="hljs-number">5.5</span>, <span class="hljs-number">9.2</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>])<br><br>criterion = nn.MSELoss()<br>loss = criterion(y_true, y_pred)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;MSELoss: <span class="hljs-subst">&#123;loss.item():<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">MSELoss: 2.375</code></pre>
<blockquote>
<p>è‡³äºä¸ºä»€ä¹ˆ API å‘½åä¸º <code>L1Loss</code> å’Œ
<code>MSELoss</code>ï¼Œå¦‚æ­¤ä¸å¯¹ç§°ï¼Œæ˜¯å› ä¸ºæ•°å­¦ä¼ ç»Ÿï¼Œ<code>L1Loss</code>
æ˜¯åŸºäº L1 èŒƒæ•°çš„ï¼Œè€Œ <code>MSELoss</code> åŸºäº L2 èŒƒæ•°çš„ï¼Œä½† MSE
æ˜¯å¹³æ–¹è€Œä¸æ˜¯å¹³æ–¹æ ¹ï¼Œä¸ºäº†é¿å…æ­§ä¹‰ï¼Œç›´æ¥ä½¿ç”¨äº† MSELossï¼Œè€Œä¸æ˜¯
L2Lossã€‚</p>
</blockquote>
<h3 id="smooth-l1">1.2.3 Smooth L1</h3>
<p>MAE å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿï¼Œä½†åœ¨ 0 å¤„ä¸å¯å¯¼ï¼ŒMSE åœ¨ 0
å¤„å…‰æ»‘ï¼Œä½†åœ¨è¯¯å·®è¾ƒå¤§æ—¶å®¹æ˜“æ¢¯åº¦çˆ†ç‚¸ã€‚äºæ˜¯æˆ‘ä»¬å°†ä¸¤è€…ç»“åˆï¼Œåœ¨ç»å¯¹å€¼å°äº 1
æ—¶ä½¿ç”¨ MSEï¼Œå¤§äº 1 æ—¶ä½¿ç”¨ MAEï¼Œå¹¶è¿›è¡Œç¼©æ”¾å’Œå¹³ç§»ï¼Œå¾—åˆ° Smooth L1
æŸå¤±å‡½æ•°ï¼Œæ—¢å…‰æ»‘åˆå¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿã€‚</p>
<p><span class="math display">$$SmoothL1=
\begin{cases}
\frac{1}{2}(y_i-\widehat{y}_i)^2,|y_i-\widehat{y}_i|&lt;1 \\
|y_i-\widehat{y}_i|-\frac{1}{2},|y_i-\widehat{y}_i|\geq1 &amp;
\end{cases}$$</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">y_true = torch.tensor([<span class="hljs-number">5.0</span>, <span class="hljs-number">6.2</span>, <span class="hljs-number">3.5</span>, <span class="hljs-number">4.0</span>])<br>y_pred = torch.tensor([<span class="hljs-number">5.5</span>, <span class="hljs-number">9.2</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>])<br><br>criterion = nn.SmoothL1Loss()<br>loss = criterion(y_true, y_pred)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;SmppthL1Loss: <span class="hljs-subst">&#123;loss.item():<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">SmppthL1Loss: 0.688</code></pre>
<p>å¯è§†åŒ–ä¸‰ä¸ªæŸå¤±å‡½æ•°ï¼ŒL1 Loss æ˜¯å°† MSE å‹ç¼© 0.5 å€ï¼Œå¹¶å°† MAE ä¸‹ç§»
0.5ï¼Œä½¿äºŒè€…å¯¹é½å¹³æ»‘ã€‚æ­¤å¤–è¿˜æœ‰å¾ˆå¤šå¯¹é½æ–¹æ³•ï¼Œæ¯”å¦‚ 0.25 å€çš„ MSE å’Œ ä¸‹ç§» 1
çš„ MAEï¼Œåœ¨ x=2 æ—¶å¯ä»¥å¯¹é½ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br>sns.set_theme()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mae</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">abs</span>(x)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mse</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> x ** <span class="hljs-number">2</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">smooth_l1</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> np.where(<span class="hljs-built_in">abs</span>(x) &lt; <span class="hljs-number">1</span>, <span class="hljs-number">0.5</span> * mse(x), mae(x) - <span class="hljs-number">0.5</span>)<br><br>x = np.arange(-<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0.01</span>)<br>plt.plot(x, mae(x), label=<span class="hljs-string">&#x27;MAE&#x27;</span>)<br>plt.plot(x, mse(x), label=<span class="hljs-string">&#x27;MSE&#x27;</span>)<br>plt.plot(x, smooth_l1(x), label=<span class="hljs-string">&#x27;Smooth L1&#x27;</span>)<br>plt.legend()<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">&lt;matplotlib.legend.Legend at 0x310ada210&gt;</code></pre>
<figure>
<img
src="https://img.zhubaoduo.com/03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•-03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•_31_1.png" srcset="/img/loading.gif" lazyload
alt="png" />
<figcaption aria-hidden="true">png</figcaption>
</figure>
<h1 id="æ•°å€¼å¾®åˆ†">2 æ•°å€¼å¾®åˆ†</h1>
<p>æŸå¤±å‡½æ•°çš„å€¼è¶Šå°ï¼Œè¯´æ˜æˆ‘ä»¬çš„å‚æ•°é€‰æ‹©çš„è¶Šåˆé€‚ã€‚æƒ³è¦æ±‚å¾—æŸå¤±å‡½æ•°çš„æœ€å°å€¼ï¼Œæœ€åŸºæœ¬çš„æƒ³æ³•å°±æ˜¯å¯¹æŸå¤±å‡½æ•°æ±‚å¯¼ï¼Œè§£å‡ºå¯¼æ•°ä¸º
0
çš„ç‚¹åˆ¤æ–­æ˜¯å¦ä¸ºæå°å€¼/æœ€å°å€¼ã€‚ç„¶è€Œå®é™…çš„å‡½æ•°ç›´æ¥æ±‚å¯¼æ˜¯å›°éš¾çš„ï¼Œä¸å®¹æ˜“å¾—åˆ°è§£æè§£ï¼Œè¿™æ—¶å¯ä»¥ä½¿ç”¨æ•°å€¼å¾®åˆ†çš„æ–¹å¼ï¼Œæ±‚åˆ°æŸç‚¹çš„å¯¼æ•°ï¼Œåœ¨å®é™…å·¥ç¨‹ä¸­éå¸¸å¸¸è§ã€‚</p>
<blockquote>
<p>æ³¨æ„ï¼šå®é™…ä¸Šï¼Œæ·±åº¦å­¦ä¹ ä¸­çš„ä¼˜åŒ–å™¨ï¼ˆOptimizerï¼‰åœ¨è®­ç»ƒæ—¶ä½¿ç”¨çš„å¹¶ä¸æ˜¯æ•°å€¼å¾®åˆ†ï¼Œè€Œæ˜¯åŸºäºè§£ææ¢¯åº¦ï¼ˆAnalytical
Gradientï¼‰ï¼Œé€šè¿‡ä¸€ä¸ªåä¸º <strong>åå‘ä¼ æ’­ï¼ˆBackpropagation,
BPï¼‰</strong>
çš„ç®—æ³•æ¥è®¡ç®—æ¢¯åº¦ï¼Œè¿ç®—æ•ˆç‡æé«˜ï¼Œè¿™é‡Œä½¿ç”¨æ•°å€¼å¾®åˆ†æ—¨åœ¨å¸®åŠ©ç†è§£æ¢¯åº¦å’Œå®ƒçš„ä½œç”¨ã€‚</p>
</blockquote>
<h2 id="å¯¼æ•°">2.1 å¯¼æ•°</h2>
<p>å›å¿†å¯¼æ•°çš„å®šä¹‰ï¼š</p>
<p><span
class="math display">$$f^{\prime}(x)=\frac{df(x)}{dx}=\lim_{\Delta
x\to0}\frac{f(x+\Delta x)-f(x)}{\Delta x}$$</span></p>
<p>å½“ <span class="math inline"><em>x</em></span> å‘ç”Ÿä¸€ä¸ªå¾®å°çš„å˜åŒ–
<span class="math inline"><em>Î”</em><em>x</em></span> æ—¶ï¼Œå‡½æ•°å€¼ <span
class="math inline"><em>f</em>(<em>x</em>)</span> ä¹Ÿä¼šå‘ç”Ÿå˜åŒ–ï¼›å½“ <span
class="math inline"><em>Î”</em><em>x</em></span> è¶‹è¿‘äº 0 æ—¶ï¼Œæ­¤æ—¶ <span
class="math inline"><em>f</em>(<em>x</em>)</span> çš„â€œå˜åŒ–ç‡â€å°±æ˜¯ <span
class="math inline"><em>x</em></span> è¿™ä¸€ç‚¹çš„å¯¼æ•°å€¼ã€‚</p>
<p>åˆ©ç”¨è¿™ä¸ªå®šä¹‰ï¼Œåœ¨æ·±åº¦å­¦ä¹ è¿™ç§é»‘ç®±ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸çŸ¥é“å¯¼æ•°è¡¨è¾¾å¼ï¼Œç”šè‡³ä¸çŸ¥é“å‡½æ•°è¡¨è¾¾å¼çš„æƒ…å†µä¸‹ï¼Œç›´æ¥ä»¥æ•°å€¼è®¡ç®—çš„æ–¹å¼ï¼Œåˆ©ç”¨å¾®å°çš„å·®åˆ†æ¥æ±‚å‡½æ•°æŸç‚¹çš„å¯¼æ•°å€¼ï¼Œè¿™ç§æ–¹æ³•ç§°ä¸º<strong>æ•°å€¼å¾®åˆ†</strong>ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">x</span>):  <br>    <span class="hljs-keyword">return</span> x ** <span class="hljs-number">2</span><br><br><span class="hljs-comment"># æ•°å€¼å¾®åˆ†æ±‚å¯¼æ•°ï¼Œx ä¸ºæ ‡é‡</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">numerical_diff</span>(<span class="hljs-params">f, x</span>):<br>    h = <span class="hljs-number">1e-4</span><br>    <span class="hljs-keyword">return</span> (f(x + h) - f(x - h)) / (h * <span class="hljs-number">2</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;x=2 å¤„çš„å¯¼æ•°ï¼š<span class="hljs-subst">&#123;numerical_diff(f, <span class="hljs-number">2</span>):<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;x=4 å¤„çš„å¯¼æ•°ï¼š<span class="hljs-subst">&#123;numerical_diff(f, <span class="hljs-number">4</span>):<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">x=2 å¤„çš„å¯¼æ•°ï¼š4.000
x=4 å¤„çš„å¯¼æ•°ï¼š8.000</code></pre>
<p>è¿™é‡Œä»¥ x
ä¸ºä¸­å¿ƒï¼Œè®¡ç®—ä¸¤è¾¹å‘ç”Ÿå¾®å°å˜åŒ–åçš„å·®åˆ†ï¼Œå¯ä»¥é¿å…åªè®¡ç®—å•å‘å¢å¤§æ—¶çš„è¯¯å·®ã€‚è¿™ç§æ–¹æ³•ç§°ä¸º
ä¸­å¿ƒå·®åˆ†ã€‚å¦å¤–ï¼Œå¾®å°å€¼ delta
ä¸èƒ½å¤ªå°ï¼Œå¦åˆ™ä¼šå¯¼è‡´æµ®ç‚¹æ•°è¡¨ç¤ºçš„ç²¾åº¦ä¸å¤Ÿï¼Œå‡ºç°èˆå…¥è¯¯å·®ã€‚</p>
<h2 id="åå¯¼æ•°">2.2 åå¯¼æ•°</h2>
<p>å¦‚æœå‡½æ•° <span class="math inline"><em>f</em></span>
çš„è‡ªå˜é‡å¹¶éå•ä¸ªå…ƒç´ ï¼Œè€Œæ˜¯å¤šä¸ªå…ƒç´ ã€‚æ¯”å¦‚ï¼š</p>
<p><span
class="math display"><em>f</em>(<em>x</em>,â€†<em>y</em>)â€„=â€„<em>x</em><sup>2</sup>â€…+â€…<em>y</em><sup>2</sup>â€…+â€…<em>x</em><em>y</em></span></p>
<p>å¯ä»¥å°†å…¶ä»–è‡ªå˜é‡éƒ½ç½®ä¸ºå¸¸æ•°ï¼Œåªæ±‚ <span
class="math inline"><em>x</em></span> å’Œ <span
class="math inline"><em>y</em></span> ä¸€ä¸ªè‡ªå˜é‡çš„å¯¼æ•°ï¼Œç§°ä¸ºåå¯¼æ•°ï¼š</p>
<p><span class="math display">$$ \frac{\partial f}{\partial x} = 2x + y
\qquad \frac{\partial f}{\partial y} = 2y + x$$</span></p>
<p>æ¨å¹¿åˆ°å¤šä¸ªè‡ªå˜é‡ï¼š</p>
<p><span class="math display">$$\frac{\partial f}{\partial
x_i}(a_1,a_2,...,a_n)=\lim_{\Delta x_i\to0}\frac{f(a_1,...a_i+\Delta
x_i,...,a_n)-f(a_1,...a_i,...,a_n)}{\Delta x_i}$$</span></p>
<p>åå¯¼æ•°åŒæ ·å¯ä»¥ç”¨æ•°å€¼å¾®åˆ†çš„æ–¹æ³•æ±‚è§£ï¼Œå³åªæ”¹å˜ä¸€ä¸ªè‡ªå˜é‡ã€å…¶å®ƒä¸å˜ï¼Œåšå·®åˆ†è®¡ç®—å‡½æ•°å€¼çš„å˜åŒ–ç‡ã€‚åº”ç”¨åˆ°æ·±åº¦å­¦ä¹ ä¸­ï¼Œå°±æ˜¯åªæ”¹å˜ä¸€ä¸ªå‚æ•°ã€å…¶ä»–ä¸å˜ï¼Œè®¡ç®—æŸå¤±å‡½æ•°çš„åå¯¼æ•°ã€‚</p>
<h2 id="æ¢¯åº¦">2.3 æ¢¯åº¦</h2>
<p>å¤šå…ƒå‡½æ•° <span
class="math inline"><em>ğ‘“</em>(<em>ğ‘¥</em><sub>1</sub>,â€†â€¦,â€†<em>ğ‘¥</em><sub><em>ğ‘›</em></sub>)</span>
å…³äºæ¯ä¸ªå˜é‡ <span
class="math inline"><em>ğ‘¥</em><sub><em>ğ‘–</em></sub></span> éƒ½æœ‰åå¯¼æ•°
<span class="math inline">$\frac{\partial f}{\partial x_i}$</span>ï¼Œåœ¨ç‚¹
<span class="math inline"><em>ğ‘</em></span>
å¤„ï¼Œè¿™äº›åå¯¼æ•°å®šä¹‰äº†ä¸€ä¸ªå‘é‡ï¼Œç§°ä¸º <span
class="math inline"><em>f</em></span> åœ¨ç‚¹ <span
class="math inline"><em>a</em></span> çš„æ¢¯åº¦ï¼š</p>
<p><span class="math display">$$\nabla f(a)=\left[\frac{\partial
f}{\partial x_1}(a),...,\frac{\partial f}{\partial
x_n}(a)\right]$$</span></p>
<p>å‡½æ•° <span class="math inline"><em>f</em></span> åœ¨ç‚¹ <span
class="math inline"><em>a</em></span> æœ‰æ— æ•°ä¸ªæ–¹å‘å¯¼æ•°ï¼Œæ²¿æ–¹å‘ <span
class="math inline"><em>dÌ‚</em></span> ç§»åŠ¨æ—¶å‡½æ•°å˜åŒ–ç‡ä¸ºï¼š</p>
<p><span
class="math display"><em>D</em><sub><em>d</em></sub><em>f</em>â€„=â€„|âˆ‡<em>f</em>|cosâ€†<em>Î¸</em></span></p>
<p>å…¶ä¸­ <span class="math inline"><em>Î¸</em></span> æ˜¯ <span
class="math inline">âˆ‡<em>f</em></span> ä¸ <span
class="math inline"><em>dÌ‚</em></span>
çš„å¤¹è§’ï¼Œè¦æƒ³æ‰¾åˆ°è®©å‡½æ•°ä¸‹é™æœ€å¿«çš„æ–¹å‘ï¼Œä¹Ÿå°±æ˜¯è®©å˜åŒ–ç‡æœ€è´Ÿï¼Œæ˜¾ç„¶å½“ <span
class="math inline">cosâ€†<em>Î¸</em>â€„=â€„âˆ’1</span>
æ—¶ï¼Œä¹Ÿå°±æ˜¯æ¢¯åº¦çš„åæ–¹å‘ï¼Œä¸‹é™æœ€å¿«ã€‚</p>
<p>åº”ç”¨åˆ°æ·±åº¦å­¦ä¹ ä¸­ï¼Œä½¿ç”¨æ•°å€¼å¾®åˆ†è®¡ç®—å‡ºåœ¨ a
ç‚¹å…³äºæ¯ä¸ªå‚æ•°çš„åå¯¼æ•°ï¼Œå¾—åˆ°çš„å‘é‡ä¹Ÿå°±æ˜¯è¯¥ç‚¹çš„æ¢¯åº¦ï¼Œæ¢¯åº¦ä»£è¡¨çš„æ˜¯å‡½æ•°å€¼å¢å¤§æœ€å¿«çš„æ–¹å‘ï¼Œå¯»æ‰¾æŸå¤±å‡½æ•°çš„æœ€å°å€¼éœ€è¦æ²¿ç€<strong>è´Ÿæ¢¯åº¦æ–¹å‘</strong>ã€‚è´Ÿæ¢¯åº¦ä»£è¡¨çš„æ˜¯å‡½æ•°å€¼å‡å°æœ€å¿«çš„æ–¹å‘ï¼Œä½†å¹¶ä¸ä¸€å®šç›´æ¥æŒ‡å‘å‡½æ•°å›¾åƒçš„æœ€ä½ç‚¹ã€‚</p>
<p>åœ¨å‡½æ•°çš„æå°å€¼ã€æå¤§å€¼å’Œéç‚¹å¤„ï¼Œæ¢¯åº¦ä¸º 0ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">w</span>):  <span class="hljs-comment"># æŸå¤±å‡½æ•°å¯ä»¥ä¸çŸ¥é“è¡¨è¾¾å¼ï¼Œä½†å¯ä»¥é€šè¿‡è®¡ç®—å¾—å‡ºç¡®å®šå‚æ•°è®¡ç®—å‡ºæŸå¤±å€¼</span><br>    w1, w2 = w<br>    <span class="hljs-keyword">return</span> w1 ** <span class="hljs-number">2</span> + w2 ** <span class="hljs-number">2</span> + <span class="hljs-number">5</span><br><br><br><span class="hljs-comment"># æ•°å€¼å¾®åˆ†æ±‚æ¢¯åº¦ï¼Œw ä¸ºå‘é‡</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_numerical_grad</span>(<span class="hljs-params">loss, w</span>):  <br>    h = <span class="hljs-number">1e-4</span><br>    grad = np.zeros_like(w)  <span class="hljs-comment"># åˆ›å»ºä¸ w ç›¸åŒå½¢çŠ¶çš„æ¢¯åº¦å‘é‡</span><br>    <br>    <span class="hljs-comment"># éå† w çš„æ¯ä¸€ä¸ªè‡ªå˜é‡</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(w.size):<br>        tmp = w[i]  <span class="hljs-comment"># ä¿å­˜å½“å‰è‡ªå˜é‡çš„å€¼</span><br>        w[i] = tmp + h  <span class="hljs-comment"># åªæ”¹å˜å½“å‰è‡ªå˜é‡çš„å€¼</span><br>        fwh1 = loss(w)  <span class="hljs-comment"># è®¡ç®— loss(w+h)</span><br>        w[i] = tmp - h  <span class="hljs-comment"># åªæ”¹å˜å½“å‰è‡ªå˜é‡çš„å€¼</span><br>        fwh2 = loss(w)  <span class="hljs-comment"># è®¡ç®— loss(w-h)</span><br>        w[i] = tmp  <span class="hljs-comment"># æ¢å¤å½“å‰è‡ªå˜é‡çš„å€¼</span><br>        <br>        grad[i] = (fwh1 - fwh2) / (<span class="hljs-number">2</span> * h)  <span class="hljs-comment"># è®¡ç®—æ¢¯åº¦</span><br>        <br>    <span class="hljs-keyword">return</span> grad<br><br><br><span class="hljs-comment"># æ•°å€¼å¾®åˆ†æ±‚æ¢¯åº¦ï¼ŒW ä¸ºè¾“å…¥çŸ©é˜µï¼Œæ¯ä¸€è¡Œä¸ºä¸€ä¸ªæ ·æœ¬</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">numerical_grad</span>(<span class="hljs-params">loss, W</span>):<br>    <span class="hljs-keyword">if</span> W.ndim == <span class="hljs-number">1</span>:  <span class="hljs-comment"># è¾“å…¥ä¸ºå‘é‡</span><br>        <span class="hljs-keyword">return</span> _numerical_grad(loss, W)<br>    <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># è¾“å…¥ä¸ºçŸ©é˜µ</span><br>        grad = np.zeros_like(W)  <span class="hljs-comment"># åˆ›å»ºä¸€ä¸ªå’Œè¾“å…¥çŸ©é˜µå½¢çŠ¶ç›¸åŒçš„æ¢¯åº¦çŸ©é˜µ</span><br>        <span class="hljs-keyword">for</span> i, w <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(W):  <span class="hljs-comment"># éå†çŸ©é˜µæ¯ä¸€è¡Œ</span><br>            grad[i] = _numerical_grad(loss, w)<br>        <span class="hljs-keyword">return</span> grad<br><br><span class="hljs-comment"># ä¸¤ä¸ªå‚æ•°ï¼Œä¸‰ä¸ªæ ·æœ¬æ±‚æ¢¯åº¦</span><br>numerical_grad(loss, np.array([[<span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>], [<span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>], [<span class="hljs-number">6.0</span>, <span class="hljs-number">7.0</span>]]))<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">array([[ 4.,  6.],
       [ 8., 10.],
       [12., 14.]])</code></pre>
<h2 id="åˆ©ç”¨æ•°å€¼å¾®åˆ†è®­ç»ƒç¥ç»ç½‘ç»œ">2.4 åˆ©ç”¨æ•°å€¼å¾®åˆ†è®­ç»ƒç¥ç»ç½‘ç»œ</h2>
<p>è¿™é‡Œä¸ä½¿ç”¨
PyTorchï¼Œæ‰‹åŠ¨å®ç°ä¸€ä¸ªä¸¤å±‚çš„ç¥ç»ç½‘ç»œï¼Œåˆ©ç”¨æ•°å€¼å¾®åˆ†çš„æ€æƒ³è®¡ç®—æ¢¯åº¦ï¼Œæ¥å®Œæˆç»å…¸æ¡ˆä¾‹â€”â€”â€”æ‰‹å†™æ•°å­—è¯†åˆ«ã€‚</p>
<p>æ²¡æœ‰æŸå¤±å‡½æ•°è¡¨è¾¾å¼å¦‚ä½•æ±‚æœ€å°å€¼ï¼Ÿé€šè¿‡å›ºå®šå…¶ä»–å‚æ•°ï¼Œåªæ”¹å˜ä¸€ä¸ªå‚æ•°ï¼Œæ±‚è§£æŸå¤±å‡½æ•°å¯¹äºè¯¥å‚æ•°çš„å¯¼æ•°ï¼Œå¯¹æ‰€æœ‰å‚æ•°åšæ­¤æ“ä½œï¼Œå¾—åˆ°åœ¨å½“å‰ç‚¹çš„æ¢¯åº¦å‘é‡ï¼Œç„¶åæŒ‰ç…§æ¢¯åº¦å‘é‡çš„åæ–¹å‘è¿›è¡Œå‚æ•°æ›´æ–°ã€‚</p>
<p>æ¿€æ´»å‡½æ•°å®ç°ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tanh</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> np.tanh(x)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> np.exp(x) / np.<span class="hljs-built_in">sum</span>(np.exp(x), axis=-<span class="hljs-number">1</span>).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<p>æŸå¤±å‡½æ•°åœ¨ 1.1.2 èŠ‚å·²ç»å®ç°å®Œæ¯•ï¼Œæ¢¯åº¦ä¸‹é™åœ¨ 2.3
èŠ‚å·²ç»å®ç°å®Œæ¯•ï¼Œè¿™é‡Œä¸å†é‡å¤ã€‚</p>
<p>å®šä¹‰ä¸¤å±‚ç¥ç»ç½‘ç»œæ¨¡å‹ï¼š</p>
<ul>
<li>è¾“å…¥å±‚ï¼šè¾“å…¥ç»´åº¦ 64ï¼Œå¯¹åº” 8 * 8 çš„å›¾ç‰‡</li>
<li>éšè—å±‚ï¼šè¾“å…¥ç»´åº¦ 50 ï¼Œç»è¿‡ Tanh æ¿€æ´»å‡½æ•°ï¼Œè¾“å‡ºç»´åº¦ 10</li>
<li>è¾“å‡ºå±‚ï¼šè¾“å…¥ç»´åº¦ 10ï¼Œç»è¿‡ Softmax æ¿€æ´»å‡½æ•°ï¼Œå¯¹åº” 10 ä¸ªæ•°å­—ç±»åˆ«</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TwoLayerNet</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, output_size, hidden_size=<span class="hljs-number">50</span>, weight_init=<span class="hljs-number">0.01</span></span>):<br>        <span class="hljs-variable language_">self</span>.param = &#123;&#125;<br>        <span class="hljs-variable language_">self</span>.param[<span class="hljs-string">&#x27;W1&#x27;</span>] = weight_init * np.random.randn(input_size, hidden_size)<br>        <span class="hljs-variable language_">self</span>.param[<span class="hljs-string">&#x27;b1&#x27;</span>] = np.zeros(hidden_size)<br>        <span class="hljs-variable language_">self</span>.param[<span class="hljs-string">&#x27;W2&#x27;</span>] = weight_init * np.random.randn(hidden_size, output_size)<br>        <span class="hljs-variable language_">self</span>.param[<span class="hljs-string">&#x27;b2&#x27;</span>] = np.zeros(output_size)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,  x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;å‰å‘ä¼ æ’­ï¼Œå®Œæˆä¸€æ¬¡é¢„æµ‹</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x (_type_): è¦é¢„æµ‹çš„æ ·æœ¬ç‰¹å¾</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            _type_: ç»è¿‡ softmax çš„é¢„æµ‹æ¦‚ç‡</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        W1, W2 = <span class="hljs-variable language_">self</span>.param[<span class="hljs-string">&#x27;W1&#x27;</span>], <span class="hljs-variable language_">self</span>.param[<span class="hljs-string">&#x27;W2&#x27;</span>]<br>        b1, b2 = <span class="hljs-variable language_">self</span>.param[<span class="hljs-string">&#x27;b1&#x27;</span>], <span class="hljs-variable language_">self</span>.param[<span class="hljs-string">&#x27;b2&#x27;</span>]<br>        <br>        a1 = x @ W1 + b1<br>        z1 = tanh(a1)<br>        a2 = z1 @ W2 + b2<br>        z2 = softmax(a2)<br>        <br>        <span class="hljs-keyword">return</span> z2<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">criterion</span>(<span class="hljs-params">self, y_proba, y_true</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;è®¡ç®—å¤šå…ƒäº¤å‰ç†µæŸå¤±</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            y_proba (_type_): é¢„æµ‹çš„æ¦‚ç‡å€¼</span><br><span class="hljs-string">            y_true (_type_): çœŸå®å€¼æ ‡ç­¾</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            _type_: æŸå¤±å€¼</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <br>        <span class="hljs-keyword">return</span> cross_entropy_loss(y_proba, y_true)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">accuracy</span>(<span class="hljs-params">self, y_proba, y_true</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;è®¡ç®—å‡†ç¡®ç‡</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x (_type_): é¢„æµ‹çš„æ¦‚ç‡å€¼</span><br><span class="hljs-string">            y_true (_type_): çœŸå®å€¼æ ‡ç­¾</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            _type_: å‡†ç¡®ç‡</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        y_pred = np.argmax(y_proba, axis=<span class="hljs-number">1</span>)<br>        correct_num = (y_pred == y_true).<span class="hljs-built_in">sum</span>()<br>        acc = correct_num / <span class="hljs-built_in">len</span>(y_true)<br>        <br>        <span class="hljs-keyword">return</span> acc<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">grad</span>(<span class="hljs-params">self, x, y_true</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;è®¡ç®—å½“å‰å‚æ•°çš„æ¢¯åº¦</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x (_type_): è¦é¢„æµ‹çš„æ ·æœ¬ç‰¹å¾</span><br><span class="hljs-string">            y_true (_type_): çœŸå®å€¼æ ‡ç­¾</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            _type_: æ¯ä¸ªæƒé‡çš„æ¢¯åº¦</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># è¿™é‡Œ w åªæ˜¯å ä½ï¼Œæ²¡æœ‰å®é™…ä½œç”¨ï¼Œå®é™…è°ƒç”¨è¿˜æ˜¯å½“å‰å¯¹è±¡çš„ criterion æ–¹æ³•</span><br>        <span class="hljs-comment"># å……å½“é€‚é…å™¨çš„ä½œç”¨</span><br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">loss_func</span>(<span class="hljs-params">w</span>):<br>            <span class="hljs-comment"># 1. æ‰§è¡Œå‰å‘ä¼ æ’­</span><br>            y_proba = <span class="hljs-variable language_">self</span>.forward(x) <br>            <span class="hljs-comment"># 2. è®¡ç®—æŸå¤±</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.criterion(y_proba, y_true)<br>        <br>        grads = &#123;&#125;<br>        <span class="hljs-comment"># ä¼ é€’çš„ param æ˜¯å¼•ç”¨ï¼Œæ‰€ä»¥åœ¨å‡½æ•°å†…ä¿®æ”¹äº† paramï¼Œä¹Ÿä¼šä¿®æ”¹å½“å‰å¯¹è±¡çš„ param</span><br>        grads[<span class="hljs-string">&#x27;W1&#x27;</span>] = numerical_grad(loss_func, <span class="hljs-variable language_">self</span>.param[<span class="hljs-string">&#x27;W1&#x27;</span>])<br>        grads[<span class="hljs-string">&#x27;b1&#x27;</span>] = numerical_grad(loss_func, <span class="hljs-variable language_">self</span>.param[<span class="hljs-string">&#x27;b1&#x27;</span>])<br>        grads[<span class="hljs-string">&#x27;W2&#x27;</span>] = numerical_grad(loss_func, <span class="hljs-variable language_">self</span>.param[<span class="hljs-string">&#x27;W2&#x27;</span>])<br>        grads[<span class="hljs-string">&#x27;b2&#x27;</span>] = numerical_grad(loss_func, <span class="hljs-variable language_">self</span>.param[<span class="hljs-string">&#x27;b2&#x27;</span>])<br>        <br>        <span class="hljs-keyword">return</span> grads<br></code></pre></td></tr></table></figure>
<p>å®šä¹‰å‡½æ•°è·å–æ•°æ®é›†ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_digits<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_data</span>():<br>    load_data = load_digits()<br>    X = load_data.data<br>    y = load_data.target.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    <br>    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=<span class="hljs-number">0.8</span>, stratify=y, random_state=<span class="hljs-number">66</span>)<br>    <br>    train_data = np.hstack([X_train, y_train])<br>    test_data  = np.hstack([X_test, y_test])<br>    <br>    <span class="hljs-keyword">return</span> train_data, test_data<br></code></pre></td></tr></table></figure>
<p>å®šä¹‰å‡½æ•°è¿›è¡Œè®­ç»ƒï¼Œè¿™é‡Œå¯ä»¥ä½¿ç”¨ <code>tensorboard</code>
åŠ¨æ€åœ°å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ã€‚ä½¿ç”¨ <code>pip install tensorboard</code>
å®‰è£…ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch=<span class="hljs-number">100</span>, batch_size=<span class="hljs-number">32</span>, lr=<span class="hljs-number">0.1</span></span>):<br>    train_data, test_data = get_data()  <span class="hljs-comment"># è·å–æ•°æ®</span><br>    train_size = train_data.shape[<span class="hljs-number">0</span>]  <span class="hljs-comment"># è®­ç»ƒé›†å¤§å°</span><br>    iter_num = train_size // batch_size + <span class="hljs-number">1</span>  <span class="hljs-comment"># æ¯ä¸ª epoch è¿­ä»£æ¬¡æ•°</span><br>    <br>    model = TwoLayerNet(input_size=<span class="hljs-number">64</span>, output_size=<span class="hljs-number">10</span>)<br>    <br>    <span class="hljs-string">&quot;&quot;&quot;åˆ›å»º SummaryWriter å¯¹è±¡&quot;&quot;&quot;</span><br>    writer = SummaryWriter(<br>            log_dir=<span class="hljs-string">f&#x27;runs/<span class="hljs-subst">&#123;time.strftime(<span class="hljs-string">&#x27;%Y-%m-%d_%H-%M-%S&#x27;</span>)&#125;</span>&#x27;</span><br>        )<br>    <br>    loss_list = []<br>    acc_list = []<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>        total_loss = <span class="hljs-number">0</span>  <span class="hljs-comment"># æ¯è½®æ€»æŸå¤±</span><br>        batch_num = <span class="hljs-number">0</span>  <span class="hljs-comment"># æ‰¹æ¬¡æ•°</span><br>        correct_num = <span class="hljs-number">0</span>  <span class="hljs-comment"># é¢„æµ‹æ­£ç¡®çš„æ•°é‡</span><br>        train_num = <span class="hljs-number">0</span>  <span class="hljs-comment"># æ€»æ ·æœ¬æ•°</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(iter_num):<br>            <span class="hljs-comment"># éšæœºè·å–ä¸€ä¸ª batch ç´¢å¼•</span><br>            batch_mask = np.random.choice(train_size, batch_size)<br>            train = train_data[batch_mask]  <span class="hljs-comment"># è·å– batch æ•°æ®</span><br>            X_train, y_train = train[:, :-<span class="hljs-number">1</span>], train[:, -<span class="hljs-number">1</span>].astype(np.int64)  <span class="hljs-comment"># åˆ’åˆ†ç‰¹å¾å’Œæ ‡ç­¾</span><br>            <br>            <span class="hljs-comment"># å‰å‘ä¼ æ’­ï¼Œé¢„æµ‹æ¦‚ç‡</span><br>            y_proba = model.forward(X_train)<br>            <span class="hljs-comment"># è®¡ç®—æŸå¤±ï¼Œcross_entropy_loss è¿”å›çš„æ˜¯æ¯æ‰¹æ¬¡çš„å¹³å‡æŸå¤±</span><br>            loss = model.criterion(y_proba, y_train)<br>            total_loss += loss<br>            batch_num += <span class="hljs-number">1</span><br>            <br>            <span class="hljs-comment"># è®¡ç®—é¢„æµ‹æ ‡ç­¾</span><br>            y_pred = y_proba.argmax(axis=<span class="hljs-number">1</span>)<br>            <span class="hljs-comment"># è®¡ç®—æ‰¹æ¬¡æ­£ç¡®ä¸ªæ•°å’Œæ‰¹æ¬¡æ•°é‡</span><br>            correct_num += (y_pred == y_train).<span class="hljs-built_in">sum</span>()<br>            train_num += <span class="hljs-built_in">len</span>(y_train)<br>            <br>            <span class="hljs-comment"># è®¡ç®—æ¢¯åº¦ï¼Œæ›´æ–°å‚æ•°</span><br>            grads = model.grad(X_train, y_train)  <br>            <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> model.param.keys():<br>                model.param[key] -= lr * grads[key]<br>            <br>            <span class="hljs-comment"># æ‰‹æ‰“è¿›åº¦æ¡</span><br>            <span class="hljs-built_in">print</span>(<br>                <span class="hljs-string">f&quot;\rEpoch: <span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>:<span class="hljs-number">0</span>&gt;<span class="hljs-number">2</span>&#125;</span>&quot;</span><br>                <span class="hljs-string">f&quot;[<span class="hljs-subst">&#123;<span class="hljs-string">&#x27;=&#x27;</span> * <span class="hljs-built_in">int</span>(batch_num / iter_num * <span class="hljs-number">30</span>):&lt;<span class="hljs-number">30</span>&#125;</span>] &quot;</span><br>                <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;batch_num / iter_num * <span class="hljs-number">100</span>:&gt;<span class="hljs-number">6.2</span>f&#125;</span>%  &quot;</span><br>                <span class="hljs-string">f&quot;Loss: <span class="hljs-subst">&#123;total_loss / batch_num:<span class="hljs-number">.3</span>f&#125;</span>  &quot;</span><br>                <span class="hljs-string">f&quot;Acc: <span class="hljs-subst">&#123;correct_num / train_num * <span class="hljs-number">100</span>:<span class="hljs-number">.3</span>f&#125;</span>%&quot;</span>, <br>                end=<span class="hljs-string">&#x27;&#x27;</span><br>            )<br>            <br>        <span class="hljs-built_in">print</span>()<br>        <br>        epoch_loss = total_loss / batch_num<br>        epoch_acc = correct_num / train_num<br>        loss_list.append(epoch_loss)<br>        acc_list.append(epoch_acc)<br>        <br>        <span class="hljs-string">&quot;&quot;&quot;è®°å½• loss å’Œ acc åˆ° Tensorboard&quot;&quot;&quot;</span><br>        writer.add_scalar(<span class="hljs-string">&#x27;loss&#x27;</span>, epoch_loss, epoch)<br>        writer.add_scalar(<span class="hljs-string">&#x27;acc&#x27;</span>, epoch_acc, epoch)<br>        <br>    <span class="hljs-keyword">return</span> model, loss_list, acc_list<br><br><br><span class="hljs-comment"># ä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œè¿™é‡Œåªè®­ç»ƒ 5 è½®</span><br>model, loss_list, acc_list = train(epoch=<span class="hljs-number">5</span>)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">Epoch: 01[==============================] 100.00%  Loss: 1.295  Acc: 65.903%
Epoch: 02[==============================] 100.00%  Loss: 0.349  Acc: 92.639%
Epoch: 03[==============================] 100.00%  Loss: 0.222  Acc: 95.139%
Epoch: 04[==============================] 100.00%  Loss: 0.156  Acc: 96.944%
Epoch: 05[==============================] 100.00%  Loss: 0.111  Acc: 97.708%</code></pre>
<p>ä½¿ç”¨ç°æˆå·¥å…· <code>tqdm</code> æ˜¾ç¤ºè¿›åº¦æ¡ï¼Œä¸éœ€è¦è‡ªå·±æ‰‹å†™
<code>print</code>ã€‚ä½¿ç”¨<code>pip install tqdm</code> å®‰è£…ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br>dataloader = <span class="hljs-built_in">range</span>(<span class="hljs-number">100000000</span>)<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):<br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tqdm(dataloader, desc=<span class="hljs-string">&#x27;è®­ç»ƒ&#x27;</span>):<br>        <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure>
<pre><code class="hljs">è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000000/100000000 [00:06&lt;00:00, 16450174.04it/s]
è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000000/100000000 [00:06&lt;00:00, 16451340.61it/s]
è®­ç»ƒ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000000/100000000 [00:06&lt;00:00, 16359374.67it/s]</code></pre>
<p>ä¹Ÿå¯ä»¥åŠ¨æ€è°ƒæ•´è¿›åº¦æ¡åæ–¹æ˜¾ç¤ºçš„å†…å®¹ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">dataloader = <span class="hljs-built_in">range</span>(<span class="hljs-number">10000</span>)<br><br>loss = <span class="hljs-number">6.0</span><br>acc = <span class="hljs-number">0.1</span><br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):<br>    loop = tqdm(dataloader, desc=<span class="hljs-string">f&#x27;Epoch <span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>&#x27;</span>)<br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> loop:<br>        loop.set_postfix(loss=loss, acc=acc)<br>        loss -= <span class="hljs-number">0.0002</span><br>        acc += <span class="hljs-number">0.00003</span><br></code></pre></td></tr></table></figure>
<pre><code class="hljs">Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:02&lt;00:00, 3789.39it/s, acc=0.4, loss=4]    
Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:02&lt;00:00, 3831.96it/s, acc=0.7, loss=2]    
Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:02&lt;00:00, 3960.02it/s, acc=1, loss=0.0002]   </code></pre>
<p>ç»˜åˆ¶æŸå¤±å‡½æ•°å’Œæ­£ç¡®ç‡å¯¹äºè®­ç»ƒè½®æ¬¡çš„æ›²çº¿å›¾ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">_, axs = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">4</span>))<br>axs[<span class="hljs-number">0</span>].plot(loss_list)<br>axs[<span class="hljs-number">1</span>].plot(acc_list)<br><br>axs[<span class="hljs-number">0</span>].set_title(<span class="hljs-string">&#x27;Loss&#x27;</span>)<br>axs[<span class="hljs-number">0</span>].set_xlabel(<span class="hljs-string">&#x27;Epoch&#x27;</span>)<br>axs[<span class="hljs-number">1</span>].set_title(<span class="hljs-string">&#x27;Accuracy&#x27;</span>)<br>axs[<span class="hljs-number">1</span>].set_xlabel(<span class="hljs-string">&#x27;Epoch&#x27;</span>)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">Text(0.5, 0, &#39;Epoch&#39;)</code></pre>
<figure>
<img
src="https://img.zhubaoduo.com/03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•-03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•_62_1.png" srcset="/img/loading.gif" lazyload
alt="png" />
<figcaption aria-hidden="true">png</figcaption>
</figure>
<p>å¦‚æœä½¿ç”¨ <code>TensorBoard</code>ï¼Œåœ¨å‘½ä»¤è¡Œä¸­è¾“å…¥
<code>tensorboard --logdir=runs</code>(runs ä¸ºä¿å­˜æ—¥å¿—æ–‡ä»¶çš„ç›®å½•)å¯åŠ¨
TensorBoardï¼Œåœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ <code>http://localhost:6006</code>ã€‚</p>
<p><img
src="https://img.zhubaoduo.com/03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•-tensorboard.jpg" srcset="/img/loading.gif" lazyload /></p>
<p>åœ¨æµ‹è¯•é›†å®Œæˆé¢„æµ‹ï¼Œè¾“å‡ºåˆ†ç±»æŠ¥å‘Šã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    train_data, test_data = get_data()  <span class="hljs-comment"># è·å–æ•°æ®</span><br>    X_test, y_test = test_data[:, :-<span class="hljs-number">1</span>], test_data[:, -<span class="hljs-number">1</span>].astype(np.int64)<br>    y_proba = model.forward(X_test)<br>    y_pred = y_proba.argmax(axis=<span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-built_in">print</span>(classification_report(y_test, y_pred))<br>    <br>    <br>test()<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">              precision    recall  f1-score   support

           0       1.00      0.97      0.99        36
           1       0.97      0.95      0.96        37
           2       1.00      1.00      1.00        35
           3       0.90      1.00      0.95        37
           4       1.00      0.94      0.97        36
           5       1.00      0.89      0.94        36
           6       0.95      1.00      0.97        36
           7       1.00      1.00      1.00        36
           8       0.90      1.00      0.95        35
           9       0.94      0.89      0.91        36

    accuracy                           0.96       360
   macro avg       0.97      0.96      0.96       360
weighted avg       0.97      0.96      0.96       360</code></pre>
<h1 id="æ¢¯åº¦ä¸‹é™å’Œä¼˜åŒ–">3 æ¢¯åº¦ä¸‹é™å’Œä¼˜åŒ–</h1>
<h2 id="æ¢¯åº¦ä¸‹é™æ³•">3.1 æ¢¯åº¦ä¸‹é™æ³•</h2>
<p>æ¢¯åº¦ä¸‹é™æ³•ï¼ˆGradient
Descentï¼‰å°±æ˜¯ä¸€ç§åˆ©ç”¨æ¢¯åº¦æœ€å°åŒ–æŸå¤±å‡½æ•°çš„è¿­ä»£ä¼˜åŒ–ç®—æ³•ã€‚æ ¸å¿ƒæ˜¯æ²¿ç€æŸå¤±å‡½æ•°çš„è´Ÿæ¢¯åº¦æ–¹å‘é€æ­¥è°ƒæ•´å‚æ•°ï¼Œä»è€Œé€¼è¿‘å‡½æ•°çš„æœ€å°å€¼ã€‚</p>
<p><img
src="https://img.zhubaoduo.com/03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•-gradient_descent.png" srcset="/img/loading.gif" lazyload /></p>
<p>æ¨¡æ‹Ÿæ¢¯åº¦ä¸‹é™ä¼˜åŒ–ç›®æ ‡å‡½æ•° <code>w1 ** 2 + w2 ** 2 + 5</code>ï¼Œç»è¿‡ 15
è½®è¿­ä»£å·²ç»éå¸¸é€¼è¿‘ç›®æ ‡å‡½æ•°çš„æœ€å°å€¼
5ï¼Œå……åˆ†ä½“ç°äº†æ¢¯åº¦ä¸‹é™å¯ä»¥é€šè¿‡è¿­ä»£å¯»æ‰¾ç›®æ ‡å‡½æ•°çš„æœ€å°å€¼ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient_descent</span>(<span class="hljs-params">loss, init_W, lr=<span class="hljs-number">0.01</span>, epochs=<span class="hljs-number">100</span></span>):<br>    w = init_W.copy()<br>    <br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        grad = numerical_grad(loss, w)<br>        w -= lr * grad<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;epoch: <span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span>, w1=<span class="hljs-subst">&#123;w[<span class="hljs-number">0</span>]:<span class="hljs-number">.3</span>f&#125;</span>, w2=<span class="hljs-subst">&#123;w[<span class="hljs-number">1</span>]:<span class="hljs-number">.3</span>f&#125;</span>, loss=<span class="hljs-subst">&#123;loss(w):<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br>        <br>    <span class="hljs-keyword">return</span> w<br><br>gradient_descent(loss, np.array([<span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>]), lr=<span class="hljs-number">0.1</span>, epochs=<span class="hljs-number">15</span>)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">epoch: 1, w1=1.600, w2=2.400, loss=13.320
epoch: 2, w1=1.280, w2=1.920, loss=10.325
epoch: 3, w1=1.024, w2=1.536, loss=8.408
epoch: 4, w1=0.819, w2=1.229, loss=7.181
epoch: 5, w1=0.655, w2=0.983, loss=6.396
epoch: 6, w1=0.524, w2=0.786, loss=5.893
epoch: 7, w1=0.419, w2=0.629, loss=5.572
epoch: 8, w1=0.336, w2=0.503, loss=5.366
epoch: 9, w1=0.268, w2=0.403, loss=5.234
epoch: 10, w1=0.215, w2=0.322, loss=5.150
epoch: 11, w1=0.172, w2=0.258, loss=5.096
epoch: 12, w1=0.137, w2=0.206, loss=5.061
epoch: 13, w1=0.110, w2=0.165, loss=5.039
epoch: 14, w1=0.088, w2=0.132, loss=5.025
epoch: 15, w1=0.070, w2=0.106, loss=5.016





array([0.07036874, 0.10555312])</code></pre>
<h2 id="è®­ç»ƒæœ¯è¯­">3.2 è®­ç»ƒæœ¯è¯­</h2>
<ul>
<li><strong>Epoch</strong>ï¼š1 ä¸ª Epoch
è¡¨ç¤ºæ¨¡å‹å®Œæ•´éå†ä¸€æ¬¡è®­ç»ƒæ•°æ®é›†çš„è¿‡ç¨‹ã€‚
å•æ¬¡éå†æ•°æ®é›†é€šå¸¸ä¸è¶³ä»¥è®©æ¨¡å‹æ”¶æ•›ï¼Œæ¨¡å‹éœ€è¦å¤šæ¬¡éå†æ•°æ®é›†æ‰èƒ½é€æ­¥ä¼˜åŒ–æ¨¡å‹å‚æ•°ã€å­¦ä¹ æ•°æ®ä¸­çš„æ¨¡å¼ï¼Œ</li>
<li><strong>Batch Size</strong>ï¼šBatch Size
æ˜¯æ¯æ¬¡è®­ç»ƒæ—¶è¾“å…¥çš„æ ·æœ¬æ•°é‡ã€‚ä¾‹å¦‚ <code>batch_size=32</code> è¡¨ç¤ºæ¯æ¬¡ç”¨
32 ä¸ªæ ·æœ¬è®¡ç®—ä¸€æ¬¡æ¢¯åº¦ï¼Œå¹¶å–å¹³å‡å€¼ä½œä¸ºæœ¬æ¬¡è¿­ä»£çš„å‚æ•°æ›´æ–°æ–¹å‘ã€‚
å°æ‰¹é‡æ•°æ®è®¡ç®—æ¢¯åº¦æ¯”å•æ ·æœ¬æ›´ç¨³å®šï¼Œæ¯”å…¨æ‰¹é‡æ›´é«˜æ•ˆã€‚å¹¶ä¸”è¾ƒå°çš„ Batch Size
å¯èƒ½å¸¦æ¥æ›´å¤šå™ªå£°ï¼Œæœ‰åŠ©äºæ¨¡å‹æ³›åŒ–ã€‚</li>
<li><strong>Iteration</strong>ï¼šä¸€æ¬¡ Iteration è¡¨ç¤ºå®Œæˆä¸€ä¸ª Batch
æ•°æ®çš„æ­£å‘ä¼ æ’­ï¼ˆé¢„æµ‹ï¼‰å’Œåå‘ä¼ æ’­ï¼ˆæ›´æ–°å‚æ•°ï¼‰çš„è¿‡ç¨‹ï¼Œä¹Ÿå°±æ˜¯è®­ç»ƒè½®æ•°å’Œæ‰¹æ¬¡æ•°çš„ä¹˜ç§¯ã€‚</li>
</ul>
<h2 id="sgd">3.3 SGD</h2>
<p>SGD(Stochastic Gradient
Descent)åŸæœ¬åªéšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬è®¡ç®—æ¢¯åº¦æ¥æ›´æ–°å‚æ•°ï¼Œä½†æ˜¯åœ¨ PyTorch
ä¸­ç»å¸¸ä½¿ç”¨ <code>optim.SGD</code> é…åˆ
<code>DataLoader</code>ï¼Œå®é™…ä¸Šæ‰§è¡Œçš„æ˜¯ Mini-Batch Gradient Descent
(å°æ‰¹é‡æ¢¯åº¦ä¸‹é™)ã€‚</p>
<blockquote>
<p>æ¯ä¸ªæ ·æœ¬éƒ½å¯¹åº”ä¸€ä¸ªè‡ªå·±çš„æŸå¤±å‡½æ•°ï¼ŒMini-Batch
çš„æ€æƒ³å°±æ˜¯é€‰å–ä¸€å°æ‰¹æ ·æœ¬ï¼Œè®¡ç®—å®ƒä»¬çš„å¹³å‡æŸå¤±å¯¹æ¨¡å‹å‚æ•°çš„æ¢¯åº¦ï¼Œç”¨æ¥è¿‘ä¼¼æ•´ä¸ªè®­ç»ƒé›†çš„æŸå¤±å‡½æ•°å¯¹å‚æ•°çš„æ¢¯åº¦ã€‚</p>
</blockquote>
<p>ç”±äº Mini-Batch
å¼•å…¥äº†æ¢¯åº¦çš„éšæœºæ€§ï¼Œè¿™é—´æ¥æé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å¹¶é¿å…è¿‡æ‹Ÿåˆã€‚</p>
<p>Mini-Batch
æ˜¯å¯¹æ•´ä¸ªè®­ç»ƒé›†çœŸå®æ¢¯åº¦çš„ä¸€ä¸ªæœ‰å™ªéŸ³çš„ä¼°è®¡ï¼Œè¿™ç§å™ªéŸ³è®©ä¼˜åŒ–è¿‡ç¨‹ä¸ä¼šç¬”ç›´åœ°å†²å‘æŸå¤±å‡½æ•°è¡¨é¢çš„æœ€å°–é”ã€æœ€ç‹­çª„çš„å±€éƒ¨æå°å€¼ï¼Œè€Œå°–é”æå°å€¼é€šå¸¸ä¸è¾ƒå·®çš„æ³›åŒ–èƒ½åŠ›ï¼ˆè¿‡æ‹Ÿåˆï¼‰ç›¸å…³ã€‚éšæœºæ€§å¸®åŠ©ä¼˜åŒ–è¿‡ç¨‹æ¢ç´¢æ›´å¹¿é˜”çš„åŒºåŸŸï¼Œæ›´å®¹æ˜“æ‰¾åˆ°å¹³å¦çš„æå°å€¼ã€‚å¹³å¦çš„æå°å€¼æ„å‘³ç€æ¨¡å‹å¯¹è¾“å…¥æ•°æ®çš„å¾®å°å˜åŒ–æ›´ä¸æ•æ„Ÿï¼Œé€šå¸¸èƒ½å¸¦æ¥æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<table>

<thead>
<tr>
<th style="text-align: left;">Batch Size</th>
<th style="text-align: left;">æ¢¯åº¦ä¼°è®¡</th>
<th style="text-align: left;">æ³›åŒ–èƒ½åŠ›</th>
<th style="text-align: left;">æ”¶æ•›é€Ÿåº¦ï¼ˆæ—¶é—´ï¼‰</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">å¤§ Batch (e.g., 256+)</td>
<td style="text-align: left;">å‡†ç¡®ç¨³å®š</td>
<td
style="text-align: left;">å€¾å‘äºæ”¶æ•›åˆ°<strong>å°–é”æå°å€¼</strong>ï¼Œæ³›åŒ–èƒ½åŠ›<strong>å¯èƒ½è¾ƒå·®</strong>ï¼ˆæ›´å®¹æ˜“è¿‡æ‹Ÿåˆï¼‰ã€‚</td>
<td style="text-align: left;">è®­ç»ƒæ—¶é—´çŸ­ï¼ˆåˆ©ç”¨å¹¶è¡Œè®¡ç®—ï¼‰</td>
</tr>
<tr>
<td style="text-align: left;">å° Batch (e.g., 16-64)</td>
<td style="text-align: left;">å™ªéŸ³å¤§</td>
<td
style="text-align: left;">å€¾å‘äºæ”¶æ•›åˆ°<strong>å¹³å¦æå°å€¼</strong>ï¼Œæ³›åŒ–èƒ½åŠ›<strong>å¼º</strong>ï¼ˆä¸å®¹æ˜“è¿‡æ‹Ÿåˆï¼‰ã€‚</td>
<td style="text-align: left;">è®­ç»ƒæ—¶é—´é•¿ï¼ˆåˆ©ç”¨æ•ˆç‡ä½ï¼‰</td>
</tr>
<tr>
<td style="text-align: left;">Full Batch (å…¨æ‰¹é‡)</td>
<td style="text-align: left;">æœ€å‡†ç¡®</td>
<td style="text-align: left;"><strong>æœ€å®¹æ˜“è¿‡æ‹Ÿåˆ</strong></td>
<td style="text-align: left;">è®­ç»ƒæ—¶é—´æœ€é•¿</td>
</tr>
</tbody>
</table>
<p>æ³¨æ„è¿™é‡Œè®¨è®ºçš„æ˜¯æ³›åŒ–èƒ½åŠ›ï¼Œè€Œä¸ä»…ä»…æ˜¯æ”¶æ•›ç¨³å®šæ€§ã€‚</p>
<p>è™½ç„¶å¤§æ‰¹é‡çš„æ¢¯åº¦æ›´æ–°åœ¨è®­ç»ƒæ—¶çœ‹èµ·æ¥æ›´ç¨³å®šã€è·¯å¾„æ›´å¹³æ»‘ï¼Œä½†å®ƒä»¬ä¼šå€¾å‘äºæ‰¾åˆ°è®­ç»ƒé›†æŸå¤±æœ€ä½ä½†æ³›åŒ–èƒ½åŠ›å·®ï¼ˆå¯¹æµ‹è¯•æ•°æ®å¾®å°å˜åŒ–æ•æ„Ÿï¼‰çš„å°–é”æå°å€¼ã€‚</p>
<p>è€Œå°æ‰¹é‡çš„è®­ç»ƒè·¯å¾„è™½ç„¶æ³¢åŠ¨ï¼Œä½†è¿™ç§æ³¢åŠ¨ï¼ˆéšæœºæ€§ï¼‰å´æ˜¯ä¸€ç§æ­£åˆ™åŒ–å½¢å¼ï¼Œå¸®åŠ©æ¨¡å‹æ‰¾åˆ°äº†ä¸€ä¸ªæ³›åŒ–æ€§èƒ½æ›´å¥½ã€æ›´é²æ£’çš„å¹³å¦æå°å€¼ã€‚</p>
<p>SGD çš„æ›´æ–°å…¬å¼ï¼š</p>
<p><span
class="math display"><em>W</em>â€„â†â€„<em>W</em>â€…âˆ’â€…<em>Î·</em>âˆ‡</span></p>
<p>SGD å®ç°ç®€å•ï¼Œç†è§£æ–¹ä¾¿ï¼Œç„¶è€Œæœ‰äº›é—®é¢˜ï¼Œæ¯”å¦‚ï¼š</p>
<ul>
<li>å±€éƒ¨æœ€ä¼˜è§£ï¼šé™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œå°¤å…¶åœ¨éå‡¸å‡½æ•°ä¸­ï¼Œéš¾ä»¥æ‰¾åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚</li>
<li>éç‚¹ï¼šé™·å…¥éç‚¹ï¼Œæ¢¯åº¦ä¸º 0ï¼Œå¯¼è‡´è®­ç»ƒåœæ»ã€‚</li>
<li>æ”¶æ•›é€Ÿåº¦æ…¢ï¼šé«˜ç»´æˆ–éå‡¸å‡½æ•°ä¸­ï¼Œæ”¶æ•›é€Ÿåº¦è¾ƒæ…¢ã€‚</li>
<li>å­¦ä¹ ç‡é€‰æ‹©ï¼šå­¦ä¹ ç‡è¿‡å¤§å¯¼è‡´éœ‡è¡æˆ–ä¸æ”¶æ•›ï¼Œè¿‡å°åˆ™æ”¶æ•›é€Ÿåº¦æ…¢ã€‚</li>
</ul>
<p><img
src="https://img.zhubaoduo.com/03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•-grad_desc_problem.png" srcset="/img/loading.gif" lazyload /></p>
<p>é’ˆå¯¹ä»¥ä¸Šé—®é¢˜ï¼Œæœ‰äº›å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•å¦‚ï¼š</p>
<ol type="1">
<li>å¼•å…¥åŠ¨é‡
<ul>
<li>Momentum</li>
</ul></li>
<li>å­¦ä¹ ç‡è¡°å‡</li>
<li>è‡ªé€‚åº”å­¦ä¹ ç‡
<ul>
<li>AdaGrad</li>
<li>RMSprop</li>
</ul></li>
<li>ç»“åˆè‡ªé€‚åº”å­¦ä¹ ç‡å’ŒåŠ¨é‡
<ul>
<li>Adam</li>
</ul></li>
</ol>
<h2 id="momentum">3.4 Momentum</h2>
<p>Momentumï¼ˆåŠ¨é‡æ³•ï¼‰æ¨¡æ‹Ÿç‰©ç†å­¦ä¸­çš„åŠ¨é‡æ¦‚å¿µã€‚åœ¨æ¢¯åº¦ä¸‹é™æ—¶ï¼Œä¸ä»…ä»…è€ƒè™‘å½“å‰æ¢¯åº¦ï¼Œè¿˜è€ƒè™‘ä¹‹å‰çš„æ¢¯åº¦æ–¹å‘ã€‚</p>
<p><span class="math display">$$v\leftarrow\alpha v+(1-\alpha)\nabla \\
W\leftarrow W-\eta v$$</span></p>
<ul>
<li><span class="math inline"><em>v</em></span>:
åŠ¨é‡ï¼Œå†å²è´Ÿæ¢¯åº¦çš„åŠ æƒå’Œ</li>
<li><span class="math inline"><em>Î±</em></span>:
åŠ¨é‡çš„è¡°å‡ç‡ï¼Œä¹Ÿå°±æ˜¯å†å²æ¢¯åº¦çš„æƒé‡ï¼Œé€šå¸¸å– 0.9</li>
<li><span class="math inline"><em>Î·</em></span>: å­¦ä¹ ç‡</li>
<li><span class="math inline">âˆ‡</span>: å½“å‰æ¢¯åº¦</li>
</ul>
<p>åŠ¨é‡æ³•é€šè¿‡ç´¯è®¡å†å²æ¢¯åº¦ï¼Œèƒ½å¤Ÿå‡ç¼“ä¼˜åŒ–è¿‡ç¨‹ä¸­çš„éœ‡è¡ï¼Œå¹¶ä¸”å¾ˆæœ‰å¯èƒ½åœ¨é‡åˆ°éç‚¹æˆ–å±€éƒ¨æœ€ä¼˜è§£æ—¶ï¼Œå†²è¿‡å»ä»è€Œå–å¾—æ›´ä¼˜è§£ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br>model = nn.Linear(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># åœ¨ SGD ä¸Šç›´æ¥ä½¿ç”¨ momentum å±æ€§</span><br>optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">0.1</span>, momentum=<span class="hljs-number">0.9</span>)<br></code></pre></td></tr></table></figure>
<ul>
<li>ä¼˜ç‚¹ï¼š
<ul>
<li>å¹³æ»‘æ¢¯åº¦ï¼Œå‡å°‘æ¢¯åº¦æ–¹å‘çš„éœ‡è¡</li>
<li>åŠ é€Ÿæ”¶æ•›ï¼Œæ¢¯åº¦æ–¹å‘ä¸€è‡´æ—¶ï¼Œå¯ä»¥åŠ é€Ÿå‚æ•°çš„æ›´æ–°</li>
<li>å¯ä»¥å¸®åŠ©æ¨¡å‹å†²å‡ºå±€éƒ¨æœ€å°å€¼</li>
</ul></li>
<li>ç¼ºç‚¹ï¼š
<ul>
<li>åŠ¨é‡ç³»æ•°éœ€è¦æ‰‹åŠ¨è°ƒæ•´</li>
<li>åŠ¨é‡è¿‡å¤§ï¼Œæ¨¡å‹å¯èƒ½è¶Šè¿‡æœ€ä¼˜è§£</li>
</ul></li>
</ul>
<h2 id="å­¦ä¹ ç‡è¡°å‡">3.5 å­¦ä¹ ç‡è¡°å‡</h2>
<p>è¾ƒå¤§çš„å­¦ä¹ ç‡å¯ä»¥åŠ å¿«æ”¶æ•›é€Ÿåº¦ï¼Œ
ä½†å¯èƒ½åœ¨æœ€ä¼˜è§£é™„è¿‘éœ‡è¡æˆ–ä¸æ”¶æ•›ï¼›è¾ƒå°çš„å­¦ä¹ ç‡å¯ä»¥æé«˜æ”¶æ•›çš„ç²¾åº¦ï¼Œä½†è®­ç»ƒé€Ÿåº¦æ…¢ï¼Œå¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜è§£ã€‚å­¦ä¹ ç‡è¡°å‡æ˜¯ä¸€ç§å¹³è¡¡ç­–ç•¥ï¼ŒåˆæœŸä½¿ç”¨è¾ƒå¤§å­¦ä¹ ç‡å¿«é€Ÿæ¥è¿‘æœ€ä¼˜è§£ï¼ŒåæœŸé€æ¸å‡å°å­¦ä¹ ç‡ï¼Œä½¿å‚æ•°æ›´ç¨³å®šåœ°æ”¶æ•›åˆ°æœ€ä¼˜è§£ã€‚</p>
<ul>
<li>ç­‰é—´éš”è¡°å‡ï¼šæ¯éš”å›ºå®šçš„è®­ç»ƒå‘¨æœŸï¼ˆepochï¼‰ï¼Œå­¦ä¹ ç‡æŒ‰ä¸€å®šçš„æ¯”ä¾‹ä¸‹é™ã€‚</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># æ¯è¿‡ 10 è½®ï¼Œå­¦ä¹ ç‡è¡°å‡ä¸ºä¹‹å‰çš„ 0.6 å€</span><br>scheduler_lr = optim.lr_scheduler.StepLR(optimizer, step_size=<span class="hljs-number">10</span>, gamma=<span class="hljs-number">0.6</span>)<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):  <span class="hljs-comment"># æ¨¡æ‹Ÿä¸€ä¸ª batch</span><br>        optimizer.step()  <span class="hljs-comment"># æ¯æ‰¹æ›´æ–°ä¼˜åŒ–å™¨</span><br>    scheduler_lr.step()  <span class="hljs-comment"># æ¯è½®æ›´æ–°å­¦ä¹ ç‡</span><br>    <span class="hljs-built_in">print</span>(scheduler_lr.get_last_lr(), end=<span class="hljs-string">&#x27; &#x27;</span>)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">[0.1] [0.1] [0.1] [0.1] [0.1] [0.1] [0.1] [0.1] [0.1] [0.06] </code></pre>
<ul>
<li>åˆ¶å®šé—´éš”è¡°å‡ï¼šåœ¨æŒ‡å®šçš„ epochï¼Œè®©å­¦ä¹ ç‡æŒ‰æ¯”ä¾‹è¡°å‡ã€‚</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># åœ¨ 10ã€50ã€100 è½®æ—¶ï¼Œå­¦ä¹ ç‡è¡°å‡ä¸º 0.6 å€</span><br>optim.lr_scheduler.MultiStepLR(optimizer, milestones=[<span class="hljs-number">10</span>, <span class="hljs-number">50</span>, <span class="hljs-number">100</span>], gamma=<span class="hljs-number">0.6</span>)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">&lt;torch.optim.lr_scheduler.MultiStepLR at 0x3160cf6b0&gt;</code></pre>
<ul>
<li>æŒ‡æ•°è¡°å‡ï¼šå­¦ä¹ ç‡æŒ‰ç…§æŒ‡æ•°å‡½æ•°è¿›è¡Œè¡°å‡ï¼Œä¸€èˆ¬åº•æ•°è¦æ¥è¿‘ 1ã€‚</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># åº•æ•°ä¸º 0.95 çš„æŒ‡æ•°è¡°å‡</span><br>optim.lr_scheduler.ExponentialLR(optimizer, gamma=<span class="hljs-number">0.95</span>)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">&lt;torch.optim.lr_scheduler.ExponentialLR at 0x316895d30&gt;</code></pre>
<h2 id="adagrad">3.6 AdaGrad</h2>
<p>Adagradï¼ˆAdaptive Gradientï¼‰æ˜¯ä¸€ç§è‡ªé€‚åº”æ¢¯åº¦ä¼˜åŒ–ç®—æ³•ï¼ŒAdagrad
çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä¸ºæ¯ä¸ªå‚æ•°ç»´æŠ¤ä¸€ä¸ªç‹¬ç«‹çš„å­¦ä¹ ç‡ã€‚å®ƒä¼šæ ¹æ®æ¯ä¸ªå‚æ•°çš„å†å²æ¢¯åº¦å¹³æ–¹å’Œæ¥è°ƒæ•´å­¦ä¹ ç‡ï¼Œå¯¹äºæ›´æ–°é¢‘ç¹çš„å‚æ•°ï¼Œå­¦ä¹ ç‡ä¼šé™ä½ï¼›å¯¹äºæ›´æ–°ä¸é¢‘ç¹çš„å‚æ•°ï¼Œå­¦ä¹ ç‡ä¼šå¢åŠ ã€‚</p>
<p><span class="math display">$$G_i \leftarrow G_i+\nabla^2 \\
W_i \leftarrow W_i-\frac{\eta}{\sqrt{G_i}+\epsilon}\nabla$$</span></p>
<ul>
<li><span class="math inline"><em>G</em><sub><em>i</em></sub></span>ï¼šç¬¬
i ä¸ªå‚æ•°çš„å†å²æ¢¯åº¦å¹³æ–¹å’Œ</li>
<li><span class="math inline"><em>Î·</em></span>ï¼šå­¦ä¹ ç‡</li>
<li><span
class="math inline"><em>Ïµ</em></span>ï¼šä¸€ä¸ªå¾ˆå°çš„å€¼ï¼Œé˜²æ­¢é™¤é›¶</li>
</ul>
<p>éšç€è®­ç»ƒè¿›è¡Œï¼Œç´¯è®¡æ¢¯åº¦å¹³æ–¹å’Œå˜å¤§ï¼Œæ‰€å¯¹åº”çš„å­¦ä¹ ç‡ä¼šé€æ¸å‡å°ï¼Œæ‰€ä»¥
AdaGrad åˆšå¼€å§‹å¯ä»¥ä½¿ç”¨è¾ƒå¤§çš„å­¦ä¹ ç‡ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">optimizer = optim.Adagrad(model.parameters(), lr=<span class="hljs-number">0.1</span>)<br></code></pre></td></tr></table></figure>
<ul>
<li>ä¼˜ç‚¹ï¼š
<ul>
<li>è‡ªé€‚åº”å­¦ä¹ ç‡ï¼Œä¸ç”¨æ‰‹åŠ¨è°ƒæ•´</li>
<li>é€‚ç”¨äºç¨€ç–ç‰¹å¾ï¼Œå¤§å¤šæ•°ç‰¹å¾å€¼ä¸º 0ï¼Œå¯¹åº”çš„æ¢¯åº¦ä¹Ÿå¯èƒ½ä¸º
0ï¼Œå¯¹åº”å‚æ•°çš„ç´¯è®¡æ¢¯åº¦å’Œè¾ƒå°ï¼Œèƒ½å¤Ÿä¿æŒè¾ƒå¤§çš„å­¦ä¹ ç‡ï¼Œä¿ƒè¿›è¿™äº›ç‰¹å¾çš„å­¦ä¹ ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨æ•°æ®ä¸­ä¿¡æ¯</li>
</ul></li>
<li>ç¼ºç‚¹ï¼š
<ul>
<li>éšç€è®­ç»ƒçš„è¿›è¡Œï¼Œå­¦ä¹ ç‡æœ€ç»ˆä¼šå‡å°åˆ°éå¸¸å°çš„å€¼ï¼Œè¿‡æ—©ä½¿å­¦ä¹ ç‡è¿‡ä½å¯èƒ½å¯¼è‡´ç®—æ³•æ— æ³•æ‰¾åˆ°æœ€ä¼˜è§£ã€‚</li>
</ul></li>
</ul>
<h2 id="rmsprop">3.7 RMSProp</h2>
<p>RMSPropï¼ˆRoot Mean Square Propagationï¼Œå‡æ–¹æ ¹ä¼ æ’­ï¼‰æ˜¯åœ¨ AdaGrad
åŸºç¡€ä¸Šçš„æ”¹è¿›ï¼Œæ—¨åœ¨è§£å†³ Adagrad
åœ¨è®­ç»ƒåæœŸå­¦ä¹ ç‡é™ä½è¿‡å¿«çš„é—®é¢˜ã€‚å®ƒå¹¶éç´¯è®¡æ¯ä¸ªå‚æ•°çš„å†å²æ¢¯åº¦å¹³æ–¹ï¼Œè€Œæ˜¯é€æ¸é—å¿˜è¿‡å»çš„æ¢¯åº¦ï¼Œé‡‡ç”¨æŒ‡æ•°ç§»åŠ¨åŠ æƒå¹³å‡ï¼Œå‘ˆæŒ‡æ•°åœ°å‡å°è¿‡å»æ¢¯åº¦çš„å°ºåº¦ã€‚</p>
<p><span class="math display">$$G_i \leftarrow \alpha G_i+
(1-\alpha)\nabla^2 \\
W_i \leftarrow W_i-\frac{\eta}{\sqrt{G_i}+\epsilon}\nabla$$</span></p>
<ul>
<li><span
class="math inline"><em>Î±</em></span>ï¼šç”¨äºæ§åˆ¶å†å²æ¢¯åº¦çš„å½±å“ç¨‹åº¦ï¼Œé€šå¸¸å–
0.9-0.99 ä¹‹é—´çš„å€¼</li>
<li><span class="math inline"><em>Î·</em></span>ï¼šå­¦ä¹ ç‡</li>
<li><span class="math inline"><em>G</em><sub><em>i</em></sub></span>ï¼šç¬¬
i ä¸ªå‚æ•°çš„è¿‘æœŸæ¢¯åº¦å¹³æ–¹çš„åŠ æƒå¹³å‡å€¼</li>
<li><span class="math inline"><em>Ïµ</em></span>ï¼šå°å¸¸æ•°é˜²æ­¢é™¤é›¶</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># alpha æ§åˆ¶å†å²æ¢¯åº¦å½±å“ç¨‹åº¦</span><br>optimizer = optim.RMSprop(model.parameters(), lr=<span class="hljs-number">0.01</span>, alpha=<span class="hljs-number">0.9</span>)<br></code></pre></td></tr></table></figure>
<p>ä¼˜ç‚¹åŒ AdaGrad
ç›¸åŒï¼Œè§£å†³äº†å­¦ä¹ ç‡è¿‡æ—©è¡°å‡çš„é—®é¢˜ï¼Œå¹¶ä¸”åœ¨éå‡¸ä¼˜åŒ–é—®é¢˜çš„è§£å†³ä¸Šè¡¨ç°è‰¯å¥½ï¼Œç¼ºç‚¹æ˜¯è¶…å‚æ•°
<span class="math inline"><em>Î±</em></span> éœ€è¦æ‰‹åŠ¨è®¾ç½®ã€‚</p>
<h2 id="adam">3.8 Adam</h2>
<p>Adamï¼ˆAdaptive Moment Estimationï¼Œè‡ªé€‚åº”çŸ©ä¼°è®¡ï¼‰ç»“åˆäº† Momentum å’Œ
RMSprop çš„ä¼˜ç‚¹ï¼ŒåŒæ—¶åˆ©ç”¨æ¢¯åº¦çš„ä¸€é˜¶çŸ©ä¼°è®¡ï¼ˆå³åŠ¨é‡ï¼‰å’ŒäºŒé˜¶çŸ©ä¼°è®¡ï¼ˆå³
RMSprop
ä¸­çš„å¹³æ–¹æ¢¯åº¦ï¼‰ï¼Œèƒ½å¤Ÿé€‚åº”æ€§åœ°è°ƒæ•´æ¯ä¸ªå‚æ•°çš„å­¦ä¹ ç‡ï¼ŒåŒæ—¶åˆ©ç”¨å†å²æ¢¯åº¦çš„ä¿¡æ¯æ¥åŠ é€Ÿè®­ç»ƒã€‚</p>
$$
<p>\</p>
<p>WW-$$</p>
<ul>
<li><span
class="math inline"><em>v</em></span>ï¼šä¸€é˜¶çŸ©ä¼°è®¡ï¼Œç±»ä¼¼åŠ¨é‡</li>
<li><span
class="math inline"><em>h</em></span>ï¼šäºŒé˜¶çŸ©ä¼°è®¡ï¼Œç±»ä¼¼å¹³æ–¹æ¢¯åº¦</li>
<li><span
class="math inline"><em>Î±</em><sub>1</sub></span>ï¼šä¸€é˜¶çŸ©ä¼°è®¡çš„æŒ‡æ•°è¡°å‡ç‡ï¼Œæ§åˆ¶å†å²æ¢¯åº¦çš„å½±å“ç¨‹åº¦ï¼Œä¸€èˆ¬å–
0.9ã€‚å€¼è¶Šå¤§ï¼Œå†å²ä¿¡æ¯çš„å½±å“è¶Šå¤§ï¼Œæ¢¯åº¦å˜åŒ–è¶Šå¹³æ»‘ã€‚</li>
<li><span
class="math inline"><em>Î±</em><sub>2</sub></span>ï¼šäºŒé˜¶çŸ©ä¼°è®¡çš„æŒ‡æ•°è¡°å‡ç‡ï¼Œæ§åˆ¶å†å²å¹³æ–¹æ¢¯åº¦çš„å½±å“ç¨‹åº¦ï¼Œä¸€èˆ¬å–
0.999ã€‚å€¼è¶Šå¤§ï¼Œå†å²ä¿¡æ¯çš„å½±å“è¶Šå¤§ï¼Œå­¦ä¹ ç‡è°ƒæ•´è¶Šå¹³æ»‘ã€‚</li>
<li><span class="math inline"><em>vÌ‚</em></span> å’Œ <span
class="math inline"><em>hÌ‚</em></span>ï¼šä¿®æ­£åçš„ä¼°è®¡ï¼Œç”±äº <span
class="math inline"><em>Î±</em></span>
åˆå§‹å€¼è¾ƒå¤§ï¼Œè€Œå†å²æ¢¯åº¦æ²¡æœ‰ç»è¿‡ç´¯è®¡è¿˜å¾ˆå°ï¼Œå½“å‰æ¢¯åº¦ä¿¡æ¯è¢«å‹ç¼©å¤ªå°ï¼Œæ•´ä¸ª
<span class="math inline"><em>v</em></span> å’Œ <span
class="math inline"><em>h</em></span>
ä¼šå¾ˆå°ï¼Œé€šè¿‡é™¤å»æŒ‡æ•°ä¿®æ­£åå·®ã€‚</li>
<li><span class="math inline"><em>t</em></span>ï¼šè¿­ä»£æ¬¡æ•°</li>
<li><span class="math inline"><em>Ïµ</em></span>ï¼šå°å¸¸æ•°é˜²æ­¢é™¤é›¶é”™è¯¯</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># beta = (0.9, 0.999) åˆ†åˆ«ä»£è¡¨ Î±1 å’Œ Î±2</span><br>optimizer = optim.Adam(model.parameters(), lr=<span class="hljs-number">0.01</span>, betas=(<span class="hljs-number">0.9</span>, <span class="hljs-number">0.999</span>))<br></code></pre></td></tr></table></figure>
<ul>
<li>ä¼˜ç‚¹
<ul>
<li>è‡ªé€‚åº”å­¦ä¹ ç‡</li>
<li>å¿«é€Ÿæ”¶æ•›</li>
<li>é€‚ç”¨ç¨€ç–æ•°æ®</li>
</ul></li>
<li>ç¼ºç‚¹
<ul>
<li>å¼ºå¤§çš„è‡ªé€‚åº”æ€§å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆ</li>
</ul></li>
</ul>
<h1 id="æ­£åˆ™åŒ–">4 æ­£åˆ™åŒ–</h1>
<p>è¿‡æ‹Ÿåˆæ˜¯åœ¨æ¨¡å‹è®­ç»ƒä¸­å¾ˆå®¹æ˜“é‡åˆ°çš„é—®é¢˜ï¼Œé€šè¿‡æ­£åˆ™åŒ–çš„æ–¹å¼å¯ä»¥é™ä½æ¨¡å‹å¤æ‚åº¦ï¼Œä»è€Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚åœ¨æ·±åº¦å­¦ä¹ ä¸­ç¥ç»ç½‘ç»œå®¹æ˜“é‡åˆ°çš„é—®é¢˜è¿˜æœ‰æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸ï¼Œå€Ÿé‰´æœºå™¨å­¦ä¹ çš„æ€è·¯ï¼Œæ‰©å±•äº†æ­£åˆ™åŒ–çš„èŒƒå›´ï¼Œå¸¸è§çš„æ­£åˆ™åŒ–æ–¹æ³•æœ‰
Batch Normalizationã€æƒå€¼è¡°å‡ã€Dropoutã€æ—©åœæ³•ç­‰ã€‚</p>
<h2 id="batch-normalization">4.1 Batch Normalization</h2>
<p>åœ¨æ·±åº¦ç¥ç»ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç”±äºå‰é¢å±‚çš„å‚æ•°æ›´æ–°ä¼šå¯¼è‡´åé¢å±‚è¾“å…¥çš„æ”¹å˜ï¼Œæ¯ä¸€å±‚è¾“å…¥çš„åˆ†å¸ƒéƒ½åœ¨ä¸æ–­å˜åŒ–ï¼Œè¿™ç§ç°è±¡è¢«ç§°ä¸ºå†…éƒ¨åå˜é‡åç§»
(Internal Covariate Shift)ã€‚è¿™ä¼šå¸¦æ¥ä»¥ä¸‹é—®é¢˜ï¼š</p>
<ul>
<li>è®­ç»ƒç¼“æ…¢ï¼š æ¯å±‚éƒ½éœ€è¦ä¸æ–­é€‚åº”æ–°çš„è¾“å…¥åˆ†å¸ƒï¼Œå¯¼è‡´å­¦ä¹ æ•ˆç‡é™ä½ã€‚</li>
<li>æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸ï¼š
è¾“å…¥åˆ†å¸ƒçš„å˜åŒ–å¯èƒ½å¯¼è‡´æ¢¯åº¦å˜å¾—è¿‡å¤§æˆ–è¿‡å°ï¼Œå½±å“è®­ç»ƒçš„ç¨³å®šæ€§ã€‚</li>
<li>å¯¹åˆå§‹åŒ–æ•æ„Ÿï¼š åˆé€‚çš„åˆå§‹åŒ–å‚æ•°å˜å¾—æ›´åŠ é‡è¦ï¼Œå¦åˆ™éš¾ä»¥è®­ç»ƒã€‚</li>
</ul>
<p>Batch Normalization
é€šè¿‡å°†æ¯å±‚ç½‘ç»œçš„è¾“å…¥å½’ä¸€åŒ–åˆ°ä¸€ä¸ªæ ‡å‡†åˆ†å¸ƒï¼Œå¯ä»¥è°ƒæ•´å„å±‚çš„æ¿€æ´»å€¼åˆ†å¸ƒä½¿å…¶æ‹¥æœ‰é€‚å½“çš„å¹¿åº¦ï¼ŒBN
å±‚é€šå¸¸æ”¾åœ¨æ¿€æ´»å‡½æ•°ä¹‹å‰ï¼Œè¿™æ„å‘³ç€ç»è¿‡ BN
å±‚ä¹‹åçš„æ•°æ®æ›´åŠ é€‚åˆæ¿€æ´»å‡½æ•°ï¼Œä¸å®¹æ˜“å‡ºç°æ¢¯åº¦çˆ†ç‚¸å’Œæ¢¯åº¦æ¶ˆå¤±ã€‚</p>
<p><span
class="math display">$$\hat{x}=\frac{x-\mu}{\sqrt{\sigma^2+\epsilon}}
\qquad y=\gamma\hat{x}+\beta$$</span></p>
<p>è®¡ç®—ä¸€ä¸ª batch ä¸­æ¯ä¸ªç‰¹å¾é€šé“çš„å‡å€¼ <span
class="math inline"><em>Î¼</em></span> å’Œæ–¹å·® <span
class="math inline"><em>Ïƒ</em></span>ï¼Œç„¶åé™¤å‡å‡å€¼é™¤æ–¹å·®è¿›è¡Œå½’ä¸€åŒ–ï¼ˆ<span
class="math inline"><em>Ïµ</em></span>ä¸ºå°å¸¸æ•°ï¼‰ï¼Œä¸ºäº†ä¿è¯ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›ï¼Œå¼•å…¥ä¸¤ä¸ªå¯å­¦ä¹ çš„å‚æ•°
<span class="math inline"><em>Î³</em></span> (ç¼©æ”¾å› å­ï¼‰å’Œ <span
class="math inline"><em>Î²</em></span>
ï¼ˆå¹³ç§»å› å­ï¼‰å¯¹å½’ä¸€åŒ–åçš„è¾“å‡ºè¿›è¡Œç¼©æ”¾å’Œå¹³ç§»ã€‚</p>
<p>ä¼˜ç‚¹ï¼š - åŠ é€Ÿè®­ç»ƒï¼šå…è®¸ä½¿ç”¨æ›´é«˜çš„å­¦ä¹ ç‡ï¼ŒåŠ å¿«æ”¶æ•›é€Ÿåº¦ã€‚ -
æé«˜æ³›åŒ–èƒ½åŠ›ï¼šåœ¨ä¸€å®šç¨‹åº¦ä¸Šå…·æœ‰æ­£åˆ™åŒ–æ•ˆæœï¼Œå› ä¸ºå®ƒåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥äº†å™ªå£°ï¼ˆç”±å°æ‰¹é‡ä¼°è®¡çš„å‡å€¼å’Œæ–¹å·®äº§ç”Ÿçš„å™ªå£°ï¼‰ã€‚
-
ç¼“è§£åˆå§‹åŒ–æ•æ„Ÿæ€§ï¼šä½¿å¾—æ¨¡å‹å¯¹å‚æ•°åˆå§‹åŒ–çš„ä¾èµ–æ€§å‡å°ï¼Œä»è€Œæé«˜äº†è®­ç»ƒçš„ç¨³å®šæ€§ã€‚</p>
<p>ç¼ºç‚¹ï¼š -
å¯¹æ‰¹æ¬¡å¤§å°æ•æ„Ÿï¼šå½“æ‰¹æ¬¡å¤§å°å¾ˆå°æ—¶ï¼Œå‡å€¼å’Œæ–¹å·®çš„ä¼°è®¡å¯èƒ½ä¸å‡†ç¡®ï¼Œå½±å“å½’ä¸€åŒ–æ•ˆæœã€‚
- åœ¨ RNN ä¸­åº”ç”¨è¾ƒä¸ºå¤æ‚ï¼šåœ¨å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ä¸­åº”ç”¨ Batch Normalization
è¾ƒä¸ºå¤æ‚ï¼Œéœ€è¦è¿›è¡Œç‰¹æ®Šçš„å¤„ç†ã€‚</p>
<p>åˆ‡æ¢æ¨¡å‹æ¨¡å¼ä¼šæœ‰ä¸åŒæœºåˆ¶ï¼š</p>
<ol type="1">
<li><strong>è®­ç»ƒæ—¶ï¼š</strong> <code>model.train()</code>
<ul>
<li>BN å±‚ä¼šè®¡ç®—å½“å‰æ‰¹æ¬¡çš„å‡å€¼ <span
class="math inline"><em>Î¼</em></span> å’Œæ–¹å·® <span
class="math inline"><em>Ïƒ</em>Â²</span>ï¼Œå¹¶å¯¹å½“å‰æ‰¹æ¬¡çš„æ•°æ®è¿›è¡Œè§„èŒƒåŒ–ã€‚</li>
<li>BN
å±‚è¿˜ä¼šç»´æŠ¤ä¸€ä¸ª<strong>å…¨å±€å‡å€¼</strong>å’Œ<strong>å…¨å±€æ–¹å·®</strong>çš„ç§»åŠ¨å¹³å‡å€¼ï¼Œç”¨äºæ¨ç†é˜¶æ®µã€‚</li>
</ul></li>
<li><strong>æ¨ç†æ—¶ï¼š</strong> <code>model.eval()</code>
<ul>
<li>æ¨ç†æ—¶ï¼Œç›´æ¥ä½¿ç”¨è®­ç»ƒé˜¶æ®µè®¡ç®—çš„<strong>å…¨å±€å‡å€¼</strong>å’Œ<strong>å…¨å±€æ–¹å·®</strong>ã€‚</li>
</ul></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string">BatchNorm1dï¼šä¸»è¦åº”ç”¨äºå…¨è¿æ¥å±‚æˆ–å¤„ç†ä¸€ç»´æ•°æ®çš„ç½‘ç»œï¼Œä¾‹å¦‚æ–‡æœ¬å¤„ç†ã€‚å®ƒæ¥æ”¶å½¢çŠ¶ä¸º (N, num_features) çš„å¼ é‡ä½œä¸ºè¾“å…¥ã€‚</span><br><span class="hljs-string">BatchNorm2dï¼šä¸»è¦åº”ç”¨äºå·ç§¯ç¥ç»ç½‘ç»œï¼Œå¤„ç†äºŒç»´å›¾åƒæ•°æ®æˆ–ç‰¹å¾å›¾ã€‚å®ƒæ¥æ”¶å½¢çŠ¶ä¸º (N, C, H, W) çš„å¼ é‡ä½œä¸ºè¾“å…¥ã€‚</span><br><span class="hljs-string">BatchNorm3dï¼šä¸»è¦ç”¨äºä¸‰ç»´å·ç§¯ç¥ç»ç½‘ç»œ (3D CNN)ï¼Œå¤„ç†ä¸‰ç»´æ•°æ®ï¼Œä¾‹å¦‚è§†é¢‘æˆ–åŒ»å­¦å›¾åƒã€‚å®ƒæ¥æ”¶å½¢çŠ¶ä¸º (N, C, D, H, W) çš„å¼ é‡ä½œä¸ºè¾“å…¥ã€‚</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>in_ = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, size=(<span class="hljs-number">8</span>, <span class="hljs-number">3</span>), dtype=torch.float32)<br>bn2d = nn.BatchNorm1d(num_features=<span class="hljs-number">3</span>)<br>bn2d(in_)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">tensor([[ 0.6912, -0.1234,  0.1234],
        [-1.8892,  1.1929,  1.4397],
        [-0.0461, -1.4397,  1.7688],
        [ 1.0598, -0.7816, -0.2057],
        [-0.7833, -1.1106, -0.5347],
        [-0.7833,  1.5220, -0.8638],
        [ 0.6912,  0.5347, -1.1929],
        [ 1.0598,  0.2057, -0.5347]], grad_fn=&lt;NativeBatchNormBackward0&gt;)</code></pre>
<h2 id="æƒå€¼è¡°å‡">4.2 æƒå€¼è¡°å‡</h2>
<p>ç”±äºæƒé‡å‚æ•°å–å€¼è¿‡å¤§æ˜¯å¾ˆå¤šè¿‡æ‹Ÿåˆäº§ç”Ÿçš„åŸå› ï¼Œå› æ­¤å¯ä»¥åœ¨å­¦ä¹ çš„è¿‡ç¨‹ä¸­å¯¹å¤§çš„æƒé‡è¿›è¡Œæƒ©ç½šï¼Œå¯ä»¥æœ‰æ•ˆåœ°æŠ‘åˆ¶è¿‡æ‹Ÿåˆï¼Œè¿™ç§æ–¹æ³•è¢«ç§°ä¸º<strong>æƒå€¼è¡°å‡</strong>ã€‚</p>
<p>ä¸€èˆ¬ä¼šå¯¹æŸå¤±å‡½æ•°åŠ ä¸Šä¸€ä¸ªæƒé‡çš„èŒƒæ•°ï¼›æœ€å¸¸è§çš„å°±æ˜¯ L2 èŒƒæ•°çš„å¹³æ–¹ï¼š
<span
class="math display">$$L^{\prime}=L+\frac{1}{2}\cdot\lambda\cdot||W||^2$$</span></p>
<ul>
<li><span class="math inline">||<em>W</em>||</span>ï¼šæƒé‡<span
class="math inline"><em>W</em>â€„=â€„(<em>w</em><sub>1</sub>,â€†<em>w</em><sub>1</sub>,â€†...,â€†<em>w</em><sub>1</sub>)</span>çš„
L2 èŒƒæ•°ï¼Œå³<span
class="math inline">$\sqrt{w_1^2+w_2^2+...+w_n^2}$</span></li>
<li><span
class="math inline"><em>Î»</em></span>ï¼šæ§åˆ¶æ­£åˆ™åŒ–å¼ºåº¦çš„è¶…å‚æ•°</li>
</ul>
<p>æƒ©ç½šé¡¹æ±‚å¯¼ä¹‹åå¾—åˆ° <span
class="math inline"><em>ğœ†</em><em>ğ‘Š</em></span>
ï¼Œæ‰€ä»¥åœ¨æ±‚æƒé‡æ¢¯åº¦æ—¶ï¼Œéœ€è¦ä¸ºä¹‹å‰è¯¯å·®åå‘ä¼ æ’­æ³•çš„ç»“æœåŠ ä¸Š <span
class="math inline"><em>ğœ†</em><em>ğ‘Š</em></span>ã€‚</p>
<h2 id="dropout">4.3 Dropout</h2>
<p>Dropoutï¼ˆéšæœºå¤±æ´»ï¼Œæš‚é€€æ³•ï¼‰æ˜¯ä¸€ç§åœ¨å­¦ä¹ çš„è¿‡ç¨‹ä¸­éšæœºå…³é—­ç¥ç»å…ƒçš„æ–¹æ³•ï¼Œé€šå¸¸æ”¾åœ¨æ¿€æ´»å‡½æ•°ä¹‹åï¼Œå…¨è¿æ¥å±‚ä¹‹å‰ã€‚</p>
<p>è®­ç»ƒæ—¶æ¯ä¸ªç¥ç»å…ƒéƒ½æœ‰æ¦‚ç‡ <span class="math inline"><em>ğ‘</em></span>
(é€šå¸¸ä¸º0.2~0.5)
è¢«ä¸´æ—¶å…³é—­ï¼Œè¿«ä½¿ç½‘ç»œä¸ä¾èµ–ç‰¹å®šç¥ç»å…ƒï¼Œå¼ºè¿«ç½‘ç»œå­¦ä¹ åˆ°æ›´åŠ é²æ£’çš„ç‰¹å¾è¡¨ç¤ºï¼ŒåŒæ—¶æœªè¢«å…³é—­çš„ç¥ç»å…ƒçš„è¾“å‡ºå€¼ä»¥
<span class="math inline">$\frac{1}{(1âˆ’ğ‘)}$</span>
çš„æ¯”ä¾‹è¿›è¡Œç¼©æ”¾ï¼Œä»¥ä¿æŒæœŸæœ›å€¼ä¸å˜ã€‚</p>
<p>ç”±äºæ¯æ¬¡ Dropout
æ˜¯éšæœºå¤±æ´»ï¼Œè¿­ä»£è®­ç»ƒä¸åŒçš„å­ç½‘ç»œï¼Œå¼•å…¥äº†éšæœºæ€§ï¼Œè¿‘ä¼¼é›†æˆ Bagging
çš„æ•ˆæœã€‚</p>
<p><img
src="https://img.zhubaoduo.com/03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•-dropout.png" srcset="/img/loading.gif" lazyload /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">z = torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br>dropout = nn.Dropout(<span class="hljs-number">0.5</span>)<br><br><span class="hljs-comment"># æ¯ä¸ªç¥ç»å…ƒçš„è¾“å‡ºéƒ½æœ‰ 50% çš„æ¦‚ç‡è¢«å¼ºåˆ¶ç½®é›¶</span><br>dropout(z)<br></code></pre></td></tr></table></figure>
<pre><code class="hljs">tensor([[ 1.7553,  0.8046, -0.0000,  0.0000, -1.1799],
        [-2.8858,  0.0000,  0.3864,  0.0000, -2.3464],
        [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000]])</code></pre>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="category-chain-item">æ·±åº¦å­¦ä¹ </a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="print-no-link">#æ·±åº¦å­¦ä¹ </a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•</div>
      <div>http://example.com/2024/08/07/å¤§æ¨¡å‹å¼€å‘/05 æ·±åº¦å­¦ä¹ /03_æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>ä½œè€…</div>
          <div>baoduozhu</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>å‘å¸ƒäº</div>
          <div>2024å¹´8æœˆ7æ—¥</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>è®¸å¯åè®®</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - ç½²å">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/08/09/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91/05%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/04_CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="04_CNNå·ç§¯ç¥ç»ç½‘ç»œ">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">04_CNNå·ç§¯ç¥ç»ç½‘ç»œ</span>
                        <span class="visible-mobile">ä¸Šä¸€ç¯‡</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/08/05/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91/05%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02_%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/" title="02_ç¥ç»ç½‘ç»œåŸºç¡€">
                        <span class="hidden-mobile">02_ç¥ç»ç½‘ç»œåŸºç¡€</span>
                        <span class="visible-mobile">ä¸‹ä¸€ç¯‡</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>ç›®å½•</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">æœç´¢</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">å…³é”®è¯</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
      <p>Â© 2025 æœ±å®é“ä¸ªäººæŠ€æœ¯ä¸“æ </p>
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        æ€»è®¿é—®é‡ 
        <span id="busuanzi_value_site_pv"></span>
         æ¬¡
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        æ€»è®¿å®¢æ•° 
        <span id="busuanzi_value_site_uv"></span>
         äºº
      </span>
    
    

  

</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ï¼Œå°†å®ƒä¿æŒåœ¨æœ€åº•éƒ¨ -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">åšå®¢åœ¨å…è®¸ JavaScript è¿è¡Œçš„ç¯å¢ƒä¸‹æµè§ˆæ•ˆæœæ›´ä½³</div>
  </noscript>
</body>
</html>
